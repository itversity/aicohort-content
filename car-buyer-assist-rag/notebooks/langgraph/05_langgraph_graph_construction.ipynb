{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Tutorial: Graph Construction\n",
        "\n",
        "## Objective\n",
        "Build the agentic workflow that connects the LLM to tools, creating a complete agent that can reason and act.\n",
        "\n",
        "## What You'll Learn\n",
        "1. Core LangGraph concepts: State, Nodes, Edges\n",
        "2. How to bind tools to an LLM\n",
        "3. Creating the Agent node (LLM decision-maker)\n",
        "4. Creating the Router function (conditional logic)\n",
        "5. Using the prebuilt ToolNode\n",
        "6. Compiling and visualizing the graph\n",
        "\n",
        "## Prerequisites\n",
        "- Completed: Notebooks 01-04 (Setup, Tools basics, Currency Converter, EMI Calculator)\n",
        "- Understanding of how tools work with `.invoke()`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: The Agent Architecture\n",
        "\n",
        "### What We're Building\n",
        "\n",
        "```\n",
        "START → Agent (LLM) → Router → [Tools or END]\n",
        "           ↑                        ↓\n",
        "           └────────────────────────┘\n",
        "```\n",
        "\n",
        "### Reference Point: LangGraph Core Concepts\n",
        "\n",
        "| Concept | Description | Our Implementation |\n",
        "|---------|-------------|-------------------|\n",
        "| **State** | Data that flows through the graph | `MessagesState` (list of messages) |\n",
        "| **Node** | A function that processes state | `agent` (LLM), `tools` (ToolNode) |\n",
        "| **Edge** | Connection between nodes | START→agent, tools→agent |\n",
        "| **Conditional Edge** | Dynamic routing based on state | agent→tools OR agent→END |\n",
        "\n",
        "### The ReAct Pattern\n",
        "\n",
        "Our agent follows the **ReAct** (Reasoning + Acting) pattern:\n",
        "\n",
        "1. **Reason:** LLM analyzes the query and available tools\n",
        "2. **Act:** LLM decides to call a tool (or respond directly)\n",
        "3. **Observe:** Tool result is added to message history\n",
        "4. **Repeat:** LLM reasons again with new information\n",
        "\n",
        "This cycle continues until the LLM has enough information to respond."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 2: Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment setup\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\"../../.env\")  # Adjust path as needed\n",
        "print(\"✅ Environment loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangGraph and LangChain imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from typing import Literal\n",
        "\n",
        "print(\"✅ All imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mermaid helper for graph visualization\n",
        "def render_mermaid(diagram_code, width=400):\n",
        "    \"\"\"Render Mermaid diagrams using mermaid.ink service.\"\"\"\n",
        "    from IPython.display import Image, display\n",
        "    import base64\n",
        "    \n",
        "    graphbytes = diagram_code.encode('utf-8')\n",
        "    base64_bytes = base64.urlsafe_b64encode(graphbytes)\n",
        "    base64_string = base64_bytes.decode('ascii')\n",
        "    url = f'https://mermaid.ink/img/{base64_string}'\n",
        "    display(Image(url=url, width=width))\n",
        "\n",
        "print(\"✅ Visualization helper defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Key Imports Explained\n",
        "\n",
        "| Import | Purpose |\n",
        "|--------|--------|\n",
        "| `StateGraph` | Creates the graph structure |\n",
        "| `MessagesState` | Prebuilt state with `messages` list |\n",
        "| `START`, `END` | Special nodes for graph entry/exit |\n",
        "| `ToolNode` | Prebuilt node that executes tools |\n",
        "| `Literal` | Type hint for router return values |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 3: Define the Tools\n",
        "\n",
        "We'll recreate the tools from previous notebooks. In a real project, you'd import these from a shared module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \n",
        "    Args:\n",
        "        amount: The amount to convert\n",
        "        from_currency: Source currency code (USD, EUR, GBP, INR, JPY)\n",
        "        to_currency: Target currency code (USD, EUR, GBP, INR, JPY)\n",
        "    \n",
        "    Returns:\n",
        "        A string with the conversion result including the exchange rate\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    \n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency {from_currency}\"\n",
        "    if to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency {to_currency}\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "print(\"✅ currency_converter tool defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \n",
        "    Args:\n",
        "        principal: The loan amount (must be greater than 0)\n",
        "        annual_interest_rate: Annual interest rate as percentage (e.g., 8.5 for 8.5%)\n",
        "        tenure_months: Loan tenure in months (must be greater than 0)\n",
        "        currency: Currency code for display (USD, EUR, GBP, INR, JPY)\n",
        "    \n",
        "    Returns:\n",
        "        A string with EMI calculation details\n",
        "    \"\"\"\n",
        "    if principal <= 0:\n",
        "        return \"Error: Principal must be greater than 0\"\n",
        "    if annual_interest_rate < 0:\n",
        "        return \"Error: Interest rate cannot be negative\"\n",
        "    if tenure_months <= 0:\n",
        "        return \"Error: Tenure must be greater than 0\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"✅ emi_calculator tool defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tools list\n",
        "tools = [currency_converter, emi_calculator]\n",
        "\n",
        "print(\"\\nTools Available:\")\n",
        "print(\"=\" * 50)\n",
        "for t in tools:\n",
        "    print(f\"  • {t.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 4: Initialize LLM with Tools\n",
        "\n",
        "The key step: **bind tools to the LLM**. This tells the LLM what tools are available and how to call them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create base LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "# Bind tools to LLM\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(\"✅ LLM initialized with tools\")\n",
        "print(f\"   Model: gemini-2.0-flash\")\n",
        "print(f\"   Tools bound: {len(tools)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: What Does `.bind_tools()` Do?\n",
        "\n",
        "When you call `llm.bind_tools(tools)`, it:\n",
        "\n",
        "1. **Extracts schemas** from each tool (name, description, parameters)\n",
        "2. **Adds tool definitions** to every LLM request\n",
        "3. **Enables tool_calls** in the LLM's response format\n",
        "\n",
        "```python\n",
        "# Without tools:\n",
        "llm.invoke(\"Convert 100 USD to EUR\")\n",
        "# Returns: AIMessage(content=\"I don't have access to exchange rates...\")\n",
        "\n",
        "# With tools:\n",
        "llm_with_tools.invoke(\"Convert 100 USD to EUR\")\n",
        "# Returns: AIMessage(tool_calls=[{name: \"currency_converter\", args: {...}}])\n",
        "```\n",
        "\n",
        "> **Key Insight:** The LLM doesn't execute tools—it only requests them. The `tool_calls` attribute contains the tool name and arguments the LLM wants to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 5: Define the Agent Node\n",
        "\n",
        "The **Agent Node** is a function that:\n",
        "1. Receives the current state (message history)\n",
        "2. Invokes the LLM\n",
        "3. Returns the LLM's response to be added to state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Agent node that invokes the LLM.\n",
        "    \n",
        "    The LLM analyzes the conversation and decides to either:\n",
        "    1. Call tools (returns AIMessage with tool_calls)\n",
        "    2. Provide final response (returns AIMessage with content)\n",
        "    \n",
        "    Args:\n",
        "        state: Current graph state containing message history\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with \"messages\" key containing the LLM response\n",
        "    \"\"\"\n",
        "    # Get all messages from state\n",
        "    messages = state[\"messages\"]\n",
        "    \n",
        "    # Invoke LLM with full conversation history\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    \n",
        "    # Return response to be added to state\n",
        "    # LangGraph automatically appends this to state[\"messages\"]\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"✅ Agent node (call_llm) defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Node Function Pattern\n",
        "\n",
        "All LangGraph node functions follow this pattern:\n",
        "\n",
        "```python\n",
        "def my_node(state: StateType) -> dict:\n",
        "    # 1. Read from state\n",
        "    data = state[\"key\"]\n",
        "    \n",
        "    # 2. Process\n",
        "    result = do_something(data)\n",
        "    \n",
        "    # 3. Return updates to state\n",
        "    return {\"key\": [result]}  # For MessagesState, values are appended\n",
        "```\n",
        "\n",
        "**Important:** With `MessagesState`, returned messages are **appended** to the existing list, not replaced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 6: Define the Router Function\n",
        "\n",
        "The **Router** examines the LLM's response and decides where to go next:\n",
        "- If LLM wants to use tools → go to `tools` node\n",
        "- If LLM is done → go to `END`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"\n",
        "    Router that determines the next node.\n",
        "    \n",
        "    Checks the last message in state:\n",
        "    - If it has tool_calls → route to \"tools\" node\n",
        "    - Otherwise → route to END (finish)\n",
        "    \n",
        "    Args:\n",
        "        state: Current graph state\n",
        "        \n",
        "    Returns:\n",
        "        Either \"tools\" string or END constant\n",
        "    \"\"\"\n",
        "    # Get the last message (most recent LLM response)\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    \n",
        "    # Check if LLM wants to call tools\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    \n",
        "    # No tool calls = LLM is done, end the conversation\n",
        "    return END\n",
        "\n",
        "print(\"✅ Router function (should_continue) defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Router Decision Logic\n",
        "\n",
        "```\n",
        "Last Message Analysis:\n",
        "┌─────────────────────────────────────────────────────────┐\n",
        "│ AIMessage                                               │\n",
        "│   ├── content: \"Here's your answer...\"                  │\n",
        "│   └── tool_calls: []  ──────────────────→ Route to END  │\n",
        "└─────────────────────────────────────────────────────────┘\n",
        "\n",
        "┌─────────────────────────────────────────────────────────┐\n",
        "│ AIMessage                                               │\n",
        "│   ├── content: \"\"                                       │\n",
        "│   └── tool_calls: [{name: \"currency_converter\", ...}]   │\n",
        "│                    └────────────────────→ Route to TOOLS│\n",
        "└─────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "The router doesn't make decisions—it just reads what the LLM decided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 7: Build the Graph\n",
        "\n",
        "Now we connect all components into an executable workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Building StateGraph...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Step 1: Initialize graph with state schema\n",
        "workflow = StateGraph(MessagesState)\n",
        "print(\"\\n1. Created StateGraph with MessagesState\")\n",
        "\n",
        "# Step 2: Add nodes\n",
        "workflow.add_node(\"agent\", call_llm)          # Our LLM decision-maker\n",
        "workflow.add_node(\"tools\", ToolNode(tools))   # Prebuilt tool executor\n",
        "print(\"2. Added nodes: 'agent', 'tools'\")\n",
        "\n",
        "# Step 3: Add entry point\n",
        "workflow.add_edge(START, \"agent\")  # Always start with agent\n",
        "print(\"3. Added edge: START → agent\")\n",
        "\n",
        "# Step 4: Add conditional routing from agent\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",           # From this node\n",
        "    should_continue,   # Use this function to decide\n",
        "    {\n",
        "        \"tools\": \"tools\",  # If returns \"tools\", go to tools node\n",
        "        END: END            # If returns END, finish\n",
        "    }\n",
        ")\n",
        "print(\"4. Added conditional edges: agent → [tools OR END]\")\n",
        "\n",
        "# Step 5: Add edge from tools back to agent (the loop)\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "print(\"5. Added edge: tools → agent (creates the loop)\")\n",
        "\n",
        "# Step 6: Compile into executable app\n",
        "app = workflow.compile()\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"✅ Graph compiled successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Graph Building Steps\n",
        "\n",
        "| Step | Method | Purpose |\n",
        "|------|--------|--------|\n",
        "| 1 | `StateGraph(MessagesState)` | Create graph with state schema |\n",
        "| 2 | `add_node(name, function)` | Register processing functions |\n",
        "| 3 | `add_edge(START, node)` | Define entry point |\n",
        "| 4 | `add_conditional_edges()` | Define dynamic routing |\n",
        "| 5 | `add_edge(node1, node2)` | Define fixed transitions |\n",
        "| 6 | `compile()` | Create executable application |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 8: Visualize the Graph\n",
        "\n",
        "LangGraph can generate a Mermaid diagram of your workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get and display the Mermaid diagram\n",
        "mermaid_diagram = app.get_graph().draw_mermaid()\n",
        "\n",
        "print(\"Graph Visualization:\")\n",
        "print(\"=\" * 50)\n",
        "render_mermaid(mermaid_diagram, width=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Also print the raw Mermaid code\n",
        "print(\"Mermaid Diagram Code:\")\n",
        "print(\"=\" * 50)\n",
        "print(mermaid_diagram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Understanding the Graph Structure\n",
        "\n",
        "```\n",
        "┌─────────┐\n",
        "│  START  │\n",
        "└────┬────┘\n",
        "     │\n",
        "     ▼\n",
        "┌─────────┐     tool_calls?      ┌─────────┐\n",
        "│  agent  │─────────YES─────────▶│  tools  │\n",
        "└────┬────┘                      └────┬────┘\n",
        "     │                                │\n",
        "     │ NO (no tool_calls)             │\n",
        "     ▼                                │\n",
        "┌─────────┐                           │\n",
        "│   END   │◀──────────────────────────┘\n",
        "└─────────┘\n",
        "```\n",
        "\n",
        "**The Loop:** After tools execute, control returns to `agent`, which can:\n",
        "- Call more tools (continue looping)\n",
        "- Provide final answer (exit to END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 9: Understanding the Execution Flow\n",
        "\n",
        "### Complete Message Flow Example\n",
        "\n",
        "```\n",
        "User: \"Convert 100 USD to EUR\"\n",
        "\n",
        "┌──────────────────────────────────────────────────────────────────┐\n",
        "│ STEP 1: START → agent                                           │\n",
        "│   State: [HumanMessage(\"Convert 100 USD to EUR\")]               │\n",
        "│   Agent receives query, decides to call tool                    │\n",
        "│   Output: AIMessage(tool_calls=[{currency_converter, args}])    │\n",
        "└──────────────────────────────────────────────────────────────────┘\n",
        "                              ↓\n",
        "┌──────────────────────────────────────────────────────────────────┐\n",
        "│ STEP 2: agent → tools (router sees tool_calls)                  │\n",
        "│   ToolNode executes currency_converter.invoke({...})            │\n",
        "│   Output: ToolMessage(content=\"Conversion Result: ...\")         │\n",
        "└──────────────────────────────────────────────────────────────────┘\n",
        "                              ↓\n",
        "┌──────────────────────────────────────────────────────────────────┐\n",
        "│ STEP 3: tools → agent                                           │\n",
        "│   Agent sees tool result, formulates final answer               │\n",
        "│   Output: AIMessage(content=\"100 USD equals 92 EUR...\")         │\n",
        "└──────────────────────────────────────────────────────────────────┘\n",
        "                              ↓\n",
        "┌──────────────────────────────────────────────────────────────────┐\n",
        "│ STEP 4: agent → END (router sees no tool_calls)                 │\n",
        "│   Execution complete!                                           │\n",
        "└──────────────────────────────────────────────────────────────────┘\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: ToolNode Behavior\n",
        "\n",
        "The prebuilt `ToolNode` automatically:\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| **Extracts tool calls** | Reads `tool_calls` from the last AIMessage |\n",
        "| **Matches tools** | Finds the right tool by name |\n",
        "| **Executes tools** | Calls `.invoke()` with the provided args |\n",
        "| **Handles parallel calls** | Uses ThreadPoolExecutor for multiple tools |\n",
        "| **Returns ToolMessages** | Creates properly formatted responses |\n",
        "\n",
        "> **Key Point:** You don't write tool execution logic—`ToolNode` handles everything!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 10: Test the Graph\n",
        "\n",
        "Let's verify the graph works with a simple test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test state with a user query\n",
        "test_state = {\n",
        "    \"messages\": [HumanMessage(content=\"Convert 100 USD to EUR\")]\n",
        "}\n",
        "\n",
        "print(\"Test Query: Convert 100 USD to EUR\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the graph\n",
        "result = app.invoke(test_state)\n",
        "\n",
        "print(\"\\nExecution Complete!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total messages in result: {len(result['messages'])}\")\n",
        "print(\"\\nFinal Response:\")\n",
        "print(\"-\" * 70)\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine all messages in the execution\n",
        "print(\"\\nMessage History:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"]):\n",
        "    msg_type = type(msg).__name__\n",
        "    print(f\"\\n[{i+1}] {msg_type}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "        print(f\"    Tool Calls: {len(msg.tool_calls)}\")\n",
        "        for tc in msg.tool_calls:\n",
        "            print(f\"      • {tc['name']}({tc['args']})\")\n",
        "    elif hasattr(msg, \"content\") and msg.content:\n",
        "        content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
        "        print(f\"    Content: {content_preview}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "| Concept | Key Takeaway |\n",
        "|---------|-------------|\n",
        "| **State** | `MessagesState` holds conversation history |\n",
        "| **bind_tools()** | Enables LLM to request tool execution |\n",
        "| **Agent Node** | Invokes LLM and returns response |\n",
        "| **Router** | Directs flow based on `tool_calls` presence |\n",
        "| **ToolNode** | Prebuilt node that executes tools automatically |\n",
        "| **The Loop** | tools → agent enables multi-step reasoning |\n",
        "\n",
        "## What You Built\n",
        "\n",
        "```\n",
        "✅ Agent node (LLM decision-maker)\n",
        "✅ Router function (conditional logic)\n",
        "✅ Tools node (executes tools)\n",
        "✅ Graph with cycle (agent ↔ tools loop)\n",
        "✅ Compiled executable application\n",
        "```\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "In the following notebooks, we'll explore different execution patterns:\n",
        "\n",
        "| Notebook | Topic | Pattern |\n",
        "|----------|-------|--------|\n",
        "| **06** | Single Tool Execution | One tool call per query |\n",
        "| **07** | Parallel Execution | Multiple independent tools |\n",
        "| **08** | Sequential Execution | Dependent tool chains |\n",
        "| **09** | Conversational Context | Multi-turn conversations |\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
