{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Sequential Tool Execution\n",
        "\n",
        "Understanding how LangGraph executes dependent tools one after another.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. **Understand sequential execution** - When tasks have dependencies, the LLM executes tools one at a time, using results from earlier tools\n",
        "2. **Recognize the sequential pattern** - Multiple separate AIMessages with tool_calls indicate sequential loops through the graph\n",
        "3. **Verify data flow** - Examine how the LLM extracts values from tool results and uses them in subsequent tool calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"‚úÖ Environment loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools\n",
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates or to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \"\"\"\n",
        "    if principal <= 0 or annual_interest_rate < 0 or tenure_months <= 0:\n",
        "        return \"Error: Invalid input parameters\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Tools defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize LLM and Build Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM and build graph\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "tools = [currency_converter, emi_calculator]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"LLM node: Calls LLM with current messages.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router: Check if agent wants to use tools.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# Build graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"llm\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"llm\")\n",
        "workflow.add_conditional_edges(\"llm\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"llm\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"‚úÖ Graph compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Query Analysis\n",
        "\n",
        "Notice the dependency indicators: \"**then**\" and \"**that amount**\" signal the second task depends on the first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sequential execution test: dependent tasks\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 1000 USD to EUR, then calculate the EMI for that amount in EUR at 7% for 48 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query Analysis:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Query: {state['messages'][0].content}\")\n",
        "print(\"\\nDependency indicators in query:\")\n",
        "print(\"  ‚Ä¢ 'then' - suggests order matters\")\n",
        "print(\"  ‚Ä¢ 'that amount' - refers to previous result\")\n",
        "print(\"  ‚Ä¢ 'in EUR' - must know converted amount first\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Execute and Analyze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the graph\n",
        "result = app.invoke(state)\n",
        "\n",
        "print(\"Execution Complete!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total messages: {len(result['messages'])} (expected: 6 for sequential)\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Sequential Tool Calls\n",
        "\n",
        "Check for **multiple separate AIMessages** with tool_calls - this is the sequential pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify sequential tool calls\n",
        "tool_call_messages = [\n",
        "    msg for msg in result['messages']\n",
        "    if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls\n",
        "]\n",
        "\n",
        "print(\"SEQUENTIAL EXECUTION VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"AIMessages with tool_calls: {len(tool_call_messages)}\")\n",
        "\n",
        "if len(tool_call_messages) > 1:\n",
        "    print(\"\\nüîÑ CONFIRMED: Sequential execution detected!\")\n",
        "    print(f\"   {len(tool_call_messages)} SEPARATE tool call requests\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Single tool call message (might be parallel)\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Tool Call Sequence:\")\n",
        "print(\"-\" * 80)\n",
        "for i, msg in enumerate(tool_call_messages, 1):\n",
        "    print(f\"\\n  Loop {i}: {msg.tool_calls[0]['name']}\")\n",
        "    print(f\"    Args: {msg.tool_calls[0]['args']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Complete Message Flow\n",
        "\n",
        "Examine all messages to see the two loops through the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine complete message flow\n",
        "print(\"COMPLETE MESSAGE FLOW\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "loop_num = 0\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    print(f\"\\n{'‚îÄ' * 80}\")\n",
        "    print(f\"MESSAGE {i}: {type(msg).__name__}\")\n",
        "    print(f\"{'‚îÄ' * 80}\")\n",
        "    \n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"  üë§ USER INPUT\")\n",
        "        print(f\"  Content: {msg.content[:60]}...\" if len(msg.content) > 60 else f\"  Content: {msg.content}\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            loop_num += 1\n",
        "            print(f\"  ü§ñ AGENT: Loop {loop_num} - Calling tool\")\n",
        "            print(f\"    Tool: {msg.tool_calls[0]['name']}\")\n",
        "            print(f\"    Args: {msg.tool_calls[0]['args']}\")\n",
        "        else:\n",
        "            print(f\"  ü§ñ AGENT: Final synthesized response\")\n",
        "            preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
        "            print(f\"  Content: {preview}\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"  üîß TOOL RESULT\")\n",
        "        print(f\"  Tool Call ID: {msg.tool_call_id[:30]}...\")\n",
        "        lines = msg.content.split('\\n')[:2]\n",
        "        for line in lines:\n",
        "            print(f\"    {line}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Flow Verification\n",
        "\n",
        "Verify the LLM correctly extracted the converted amount from the first tool and used it in the second tool call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data flow between tools\n",
        "print(\"DATA FLOW VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get the currency conversion result\n",
        "currency_result = result['messages'][2]  # First ToolMessage\n",
        "print(\"STEP 1 - Currency Conversion Result:\")\n",
        "print(f\"  {currency_result.content}\")\n",
        "\n",
        "# Get the EMI tool call\n",
        "emi_call = result['messages'][3]  # Second AIMessage with tool_calls\n",
        "print(\"\\nSTEP 2 - EMI Calculator Called With:\")\n",
        "for key, value in emi_call.tool_calls[0]['args'].items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"DEPENDENCY VERIFICATION:\")\n",
        "print(\"-\" * 80)\n",
        "extracted_principal = emi_call.tool_calls[0]['args'].get('principal')\n",
        "extracted_currency = emi_call.tool_calls[0]['args'].get('currency')\n",
        "print(f\"  ‚úÖ LLM extracted principal: {extracted_principal} {extracted_currency}\")\n",
        "print(f\"  ‚úÖ This matches the conversion result from Step 1!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examine Individual Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show final response\n",
        "print(\"\\nFINAL RESPONSE:\")\n",
        "print(\"=\" * 80)\n",
        "print(result['messages'][-1].content)\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Streaming Execution\n",
        "\n",
        "Observe the multiple loops in real-time through streaming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming view\n",
        "state_stream = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 1000 USD to EUR, then calculate the EMI for that amount in EUR at 7% for 48 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"STREAMING EXECUTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Watch the MULTIPLE loops in sequential execution...\\n\")\n",
        "\n",
        "step_count = 0\n",
        "loop_count = 0\n",
        "\n",
        "for event in app.stream(state_stream):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: '{node_name}'\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            for msg in data[\"messages\"]:\n",
        "                if isinstance(msg, AIMessage):\n",
        "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "                        loop_count += 1\n",
        "                        print(f\"  üîÑ LOOP {loop_count}: Calling {msg.tool_calls[0]['name']}\")\n",
        "                        print(f\"     Args: {msg.tool_calls[0]['args']}\")\n",
        "                    else:\n",
        "                        print(f\"  üí¨ Final response generated\")\n",
        "                        \n",
        "                elif isinstance(msg, ToolMessage):\n",
        "                    print(f\"  ‚úÖ Tool executed\")\n",
        "                    first_line = msg.content.split('\\n')[0]\n",
        "                    print(f\"     Result: {first_line}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"Total steps: {step_count}\")\n",
        "print(f\"Total loops (agent ‚Üí tools): {loop_count}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "‚úÖ **Sequential execution** - When tasks have dependencies (e.g., \"then\", \"that amount\"), the LLM executes tools one at a time, using results from earlier tools to inform later ones\n",
        "\n",
        "‚úÖ **Sequential pattern** - Multiple separate AIMessages with tool_calls (e.g., AIMessage‚ÇÅ ‚Üí ToolMessage‚ÇÅ ‚Üí AIMessage‚ÇÇ ‚Üí ToolMessage‚ÇÇ) indicating 2+ loops through the graph, resulting in 6+ total messages\n",
        "\n",
        "‚úÖ **Data flow verification** - The LLM extracts values from ToolMessages (e.g., \"920 EUR\" from conversion) and uses them as parameters in subsequent tool calls (e.g., `principal=920, currency=\"EUR\"` for EMI)\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Next, we'll explore **conversational context** where the agent maintains state across multiple user turns in a conversation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
