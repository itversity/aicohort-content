{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Tutorial: Graph Construction\n",
        "\n",
        "**Objective:** Build the agentic workflow that connects LLM and tools.\n",
        "\n",
        "**What We'll Build:**\n",
        "```\n",
        "START → Agent (LLM) → Router → [Tools or END]\n",
        "           ↑                        ↓\n",
        "           └────────────────────────┘\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Mermaid\n",
        "\n",
        "Define render_mermaid function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mermaid helper for visualization\n",
        "def render_mermaid(diagram_code, width=400):\n",
        "    '''Helper function to render Mermaid diagrams using mermaid.ink'''\n",
        "    from IPython.display import Image, display\n",
        "    import base64\n",
        "    \n",
        "    graphbytes = diagram_code.encode('utf-8')\n",
        "    base64_bytes = base64.urlsafe_b64encode(graphbytes)\n",
        "    base64_string = base64_bytes.decode('ascii')\n",
        "    url = f'https://mermaid.ink/img/{base64_string}'\n",
        "    display(Image(url=url, width=width))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recreate Tools\n",
        "\n",
        "Copy the tools from Notebook 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tools defined\n",
            "   • currency_converter\n",
            "   • emi_calculator\n"
          ]
        }
      ],
      "source": [
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Args:\n",
        "        amount: The amount to convert\n",
        "        from_currency: Source currency code (USD, EUR, GBP, INR, JPY)\n",
        "        to_currency: Target currency code (USD, EUR, GBP, INR, JPY)\n",
        "    \n",
        "    Returns:\n",
        "        A string with the conversion result including the exchange rate\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    \n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency {from_currency}\"\n",
        "    if to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency {to_currency}\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "    \n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Args:\n",
        "        principal: The loan amount\n",
        "        annual_interest_rate: Annual interest rate as percentage (e.g., 8.5 for 8.5%)\n",
        "        tenure_months: Loan tenure in months\n",
        "        currency: Currency code for display\n",
        "    \n",
        "    Returns:\n",
        "        A string with EMI calculation details\n",
        "    \"\"\"\n",
        "    if principal <= 0:\n",
        "        return \"Error: Principal must be greater than 0\"\n",
        "    if annual_interest_rate < 0:\n",
        "        return \"Error: Interest rate cannot be negative\"\n",
        "    if tenure_months <= 0:\n",
        "        return \"Error: Tenure must be greater than 0\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"✅ Tools defined\")\n",
        "print(f\"   • {currency_converter.name}\")\n",
        "print(f\"   • {emi_calculator.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize LLM with Tools\n",
        "\n",
        "Bind tools to the LLM so it knows they're available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment\n",
        "load_dotenv(\"../../.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LLM initialized with tools\n",
            "   Model: gemini-2.5-pro\n",
            "   Tools bound: 2\n"
          ]
        }
      ],
      "source": [
        "# Create base LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024,\n",
        "    project=os.getenv(\"GOOGLE_PROJECT_ID\"),\n",
        "    location=os.getenv(\"GOOGLE_REGION\")\n",
        ")\n",
        "\n",
        "# Define tools list\n",
        "tools = [currency_converter, emi_calculator]\n",
        "\n",
        "# Bind tools to LLM\n",
        "# This tells the LLM: \"You can call these tools when needed\"\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(\"✅ LLM initialized with tools\")\n",
        "print(f\"   Model: gemini-2.5-pro\")\n",
        "print(f\"   Tools bound: {len(tools)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Graph Components\n",
        "\n",
        "### Component 1: Agent Node\n",
        "\n",
        "The agent calls the LLM and returns its decision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "\n",
        "from langgraph.graph import MessagesState\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Agent node (call_llm) defined\n"
          ]
        }
      ],
      "source": [
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Agent node that invokes the LLM.\n",
        "    \n",
        "    The LLM analyzes the conversation and decides to either:\n",
        "    1. Call tools (returns AIMessage with tool_calls)\n",
        "    2. Provide final response (returns AIMessage with content)\n",
        "    \n",
        "    Args:\n",
        "        state: Current graph state with message history\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with new messages to append\n",
        "    \"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"✅ Agent node (call_llm) defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Component 2: Router Function\n",
        "\n",
        "Decides the next step based on LLM's response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Router (should_continue) defined\n"
          ]
        }
      ],
      "source": [
        "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
        "    \"\"\"\n",
        "    Router that determines next node.\n",
        "    \n",
        "    Checks the last message:\n",
        "    - If it has tool_calls → route to \"tools\" node\n",
        "    - Otherwise → route to END (finish)\n",
        "    \n",
        "    Args:\n",
        "        state: Current graph state\n",
        "        \n",
        "    Returns:\n",
        "        Either \"tools\" string or END constant\n",
        "    \"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    \n",
        "    # If LLM made tool calls, execute them\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    \n",
        "    # Otherwise, we're done\n",
        "    return END\n",
        "\n",
        "print(\"✅ Router (should_continue) defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the Graph\n",
        "\n",
        "Connect all components into an executable workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building StateGraph...\n",
            "\n",
            "✅ Graph compiled successfully!\n",
            "\n",
            "Graph Structure:\n",
            "  START → agent → [router decision]\n",
            "            ↓           ↓\n",
            "          END  ←──  tools\n",
            "                      ↓\n",
            "                    agent (loop)\n"
          ]
        }
      ],
      "source": [
        "print(\"Building StateGraph...\\n\")\n",
        "\n",
        "# Initialize graph with MessagesState\n",
        "workflow = StateGraph(MessagesState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"agent\", call_llm)           # LLM decision-maker\n",
        "workflow.add_node(\"tools\", ToolNode(tools))    # Tool executor\n",
        "\n",
        "# Add edges\n",
        "workflow.add_edge(START, \"agent\")  # Always start with agent\n",
        "\n",
        "# Add conditional edge from agent\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",           # From this node\n",
        "    should_continue,   # Use this function to decide\n",
        "    {\n",
        "        \"tools\": \"tools\",  # If returns \"tools\", go to tools node\n",
        "        END: END            # If returns END, finish\n",
        "    }\n",
        ")\n",
        "\n",
        "# After tools execute, loop back to agent\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# Compile into executable app\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"✅ Graph compiled successfully!\")\n",
        "print(\"\\nGraph Structure:\")\n",
        "print(\"  START → agent → [router decision]\")\n",
        "print(\"            ↓           ↓\")\n",
        "print(\"          END  ←──  tools\")\n",
        "print(\"                      ↓\")\n",
        "print(\"                    agent (loop)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the Graph\n",
        "\n",
        "Generate and render the Mermaid diagram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/LS0tCmNvbmZpZzoKICBmbG93Y2hhcnQ6CiAgICBjdXJ2ZTogbGluZWFyCi0tLQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA-X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCWFnZW50KGFnZW50KQoJdG9vbHModG9vbHMpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJX19zdGFydF9fIC0tPiBhZ2VudDsKCWFnZW50IC0uLT4gX19lbmRfXzsKCWFnZW50IC0uLT4gdG9vbHM7Cgl0b29scyAtLT4gYWdlbnQ7CgljbGFzc0RlZiBkZWZhdWx0IGZpbGw6I2YyZjBmZixsaW5lLWhlaWdodDoxLjIKCWNsYXNzRGVmIGZpcnN0IGZpbGwtb3BhY2l0eTowCgljbGFzc0RlZiBsYXN0IGZpbGw6I2JmYjZmYwo=\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get Mermaid diagram from graph\n",
        "mermaid_diagram = app.get_graph().draw_mermaid()\n",
        "\n",
        "# Render it\n",
        "render_mermaid(mermaid_diagram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Flow\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "1. **State = Messages List**\n",
        "   - Every node reads `state[\"messages\"]`\n",
        "   - Every node returns `{\"messages\": [new_messages]}`\n",
        "   - LangGraph auto-appends new messages to state\n",
        "\n",
        "2. **The Cycle Enables Reasoning**\n",
        "   ```\n",
        "   Agent → Tools → Agent → Tools → Agent → END\n",
        "   ```\n",
        "   - Agent can call tools multiple times\n",
        "   - Each loop refines understanding\n",
        "   - Terminates when agent has enough info\n",
        "\n",
        "3. **Router Controls Flow**\n",
        "   - Checks if LLM wants to use tools\n",
        "   - Routes to `tools` or `END` accordingly\n",
        "   - Purely conditional - no hardcoded logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Basic Execution\n",
        "\n",
        "Quick sanity check before detailed testing in next notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Query: Convert 100 USD to EUR\n",
            "\n",
            "Agent Response:\n",
            "======================================================================\n",
            "100 USD is equal to 92 EUR.\n",
            "\n",
            "✅ Graph execution successful!\n"
          ]
        }
      ],
      "source": [
        "# Create test state\n",
        "test_state = {\"messages\": [HumanMessage(content=\"Convert 100 USD to EUR\")]}\n",
        "\n",
        "# Execute\n",
        "result = app.invoke(test_state)\n",
        "\n",
        "# Display result\n",
        "print(\"Test Query: Convert 100 USD to EUR\\n\")\n",
        "print(\"Agent Response:\")\n",
        "print(\"=\" * 70)\n",
        "final_message = result[\"messages\"][-1]\n",
        "print(final_message.content)\n",
        "print(\"\\n✅ Graph execution successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ✅ Graph Constructed!\n",
        "\n",
        "**Built:**\n",
        "- ✅ Agent node (LLM decision-maker)\n",
        "- ✅ Router function (conditional logic)\n",
        "- ✅ Tools node (executes tools in parallel)\n",
        "- ✅ Graph with cycle (agent ↔ tools loop)\n",
        "\n",
        "**Verified:**\n",
        "- ✅ Graph compiles without errors\n",
        "- ✅ Mermaid visualization renders\n",
        "- ✅ Basic execution works\n",
        "\n",
        "**Next:** Notebook 4 - Single Tool Execution (detailed execution analysis)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
