{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Tutorial: Conversational Context\n",
        "\n",
        "## Objective\n",
        "Understand how MessagesState maintains conversation history across multiple turns, enabling the agent to reference previous exchanges.\n",
        "\n",
        "## What You'll Learn\n",
        "1. How state preserves conversation history\n",
        "2. Multi-turn conversation patterns\n",
        "3. Context-aware tool usage (referencing previous results)\n",
        "4. Starting fresh conversations vs continuing\n",
        "5. Message accumulation and context growth\n",
        "\n",
        "## Prerequisites\n",
        "- Completed: Notebook 08 (Sequential Execution)\n",
        "- Understanding of message flow in tool-calling agents\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: The Conversational Context Pattern\n",
        "\n",
        "### How Context Works in LangGraph\n",
        "\n",
        "```\n",
        "Turn 1: User asks about currency conversion\n",
        "  ‚Üí State: [Human1, AI1(tool), Tool1, AI1(response)]\n",
        "\n",
        "Turn 2: User references \"that amount\" for EMI\n",
        "  ‚Üí State: [Human1, AI1, Tool1, AI1, Human2, AI2(tool), Tool2, AI2(response)]\n",
        "  ‚Üí LLM sees ENTIRE history, understands \"that amount\"\n",
        "\n",
        "Turn 3: User asks \"what did you calculate?\"\n",
        "  ‚Üí State: [...all previous..., Human3, AI3(response)]\n",
        "  ‚Üí LLM can recall any past exchange\n",
        "```\n",
        "\n",
        "### Reference Point: State Persistence Pattern\n",
        "\n",
        "```python\n",
        "# The key pattern for multi-turn conversations:\n",
        "state = {\"messages\": [HumanMessage(\"Turn 1\")]}\n",
        "state = app.invoke(state)  # State grows with responses\n",
        "\n",
        "state[\"messages\"].append(HumanMessage(\"Turn 2\"))  # Add next query\n",
        "state = app.invoke(state)  # LLM sees FULL history\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Message Accumulation\n",
        "\n",
        "| Turn | User Action | State Size | LLM Context |\n",
        "|------|-------------|------------|-------------|\n",
        "| 1 | Initial query | 1 ‚Üí 4 messages | Current query only |\n",
        "| 2 | Follow-up | 5 ‚Üí 8+ messages | All of Turn 1 + Turn 2 |\n",
        "| 3 | Reference past | 9+ messages | Complete history |\n",
        "\n",
        "**Key Insight:** State only grows, never shrinks. The LLM sees everything!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 2: Setup\n",
        "\n",
        "Build the financial assistant graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"‚úÖ Environment loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools\n",
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates or to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \"\"\"\n",
        "    if principal <= 0 or annual_interest_rate < 0 or tenure_months <= 0:\n",
        "        return \"Error: Invalid input parameters\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Tools defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM and build graph\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "tools = [currency_converter, emi_calculator]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"Agent node: Calls LLM with current messages.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router: Check if agent wants to use tools.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# Build graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"agent\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"‚úÖ Graph compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 3: Multi-Turn Conversation Example\n",
        "\n",
        "We'll simulate a realistic conversation where each turn builds on previous context.\n",
        "\n",
        "**Conversation Plan:**\n",
        "1. Turn 1: Ask about currency conversion\n",
        "2. Turn 2: Reference \"that amount\" for EMI calculation\n",
        "3. Turn 3: Ask about previous calculations (no tool needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize conversation state\n",
        "conversation = {\n",
        "    \"messages\": []\n",
        "}\n",
        "\n",
        "print(\"Starting Multi-Turn Conversation\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Turn 1: Initial Query (Currency Conversion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 1: Currency conversion\n",
        "print(\"\\n\" + \"‚îÄ\" * 80)\n",
        "print(\"TURN 1\")\n",
        "print(\"‚îÄ\" * 80)\n",
        "\n",
        "user_query_1 = \"Convert 50000 USD to INR\"\n",
        "print(f\"üë§ User: {user_query_1}\")\n",
        "\n",
        "# Add user message and invoke\n",
        "conversation[\"messages\"].append(HumanMessage(content=user_query_1))\n",
        "conversation = app.invoke(conversation)\n",
        "\n",
        "print(f\"\\nü§ñ Assistant: {conversation['messages'][-1].content}\")\n",
        "print(f\"\\nüìä State size: {len(conversation['messages'])} messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Turn 2: Reference Previous Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 2: EMI calculation referencing previous conversion\n",
        "print(\"\\n\" + \"‚îÄ\" * 80)\n",
        "print(\"TURN 2\")\n",
        "print(\"‚îÄ\" * 80)\n",
        "\n",
        "user_query_2 = \"Calculate EMI for that INR amount at 8.5% for 60 months\"\n",
        "print(f\"üë§ User: {user_query_2}\")\n",
        "print(\"\\n   Note: 'that INR amount' references Turn 1's result!\")\n",
        "\n",
        "# Add user message and invoke\n",
        "conversation[\"messages\"].append(HumanMessage(content=user_query_2))\n",
        "conversation = app.invoke(conversation)\n",
        "\n",
        "print(f\"\\nü§ñ Assistant: {conversation['messages'][-1].content}\")\n",
        "print(f\"\\nüìä State size: {len(conversation['messages'])} messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Turn 3: Ask About Previous Calculations (No Tool Needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 3: Simple recall question\n",
        "print(\"\\n\" + \"‚îÄ\" * 80)\n",
        "print(\"TURN 3\")\n",
        "print(\"‚îÄ\" * 80)\n",
        "\n",
        "user_query_3 = \"What was the monthly EMI you calculated?\"\n",
        "print(f\"üë§ User: {user_query_3}\")\n",
        "print(\"\\n   Note: Agent should answer from memory, no tool needed!\")\n",
        "\n",
        "# Add user message and invoke\n",
        "conversation[\"messages\"].append(HumanMessage(content=user_query_3))\n",
        "conversation = app.invoke(conversation)\n",
        "\n",
        "print(f\"\\nü§ñ Assistant: {conversation['messages'][-1].content}\")\n",
        "print(f\"\\nüìä State size: {len(conversation['messages'])} messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 4: Examine the Conversation State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"COMPLETE CONVERSATION STATE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "turn_num = 0\n",
        "for i, msg in enumerate(conversation[\"messages\"], 1):\n",
        "    if isinstance(msg, HumanMessage):\n",
        "        turn_num += 1\n",
        "        print(f\"\\n{'‚îÄ' * 80}\")\n",
        "        print(f\"TURN {turn_num}\")\n",
        "        print(f\"{'‚îÄ' * 80}\")\n",
        "        print(f\"[{i}] üë§ USER: {msg.content[:60]}...\" if len(msg.content) > 60 else f\"[{i}] üë§ USER: {msg.content}\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"[{i}] ü§ñ AGENT: Calling {msg.tool_calls[0]['name']}\")\n",
        "        else:\n",
        "            preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
        "            print(f\"[{i}] ü§ñ AGENT: {preview}\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        first_line = msg.content.split('\\n')[0]\n",
        "        print(f\"[{i}] üîß TOOL: {first_line}\")\n",
        "\n",
        "print(f\"\\n{'=' * 80}\")\n",
        "print(f\"Total messages in state: {len(conversation['messages'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: How Context Enables Understanding\n",
        "\n",
        "| Turn | User Said | LLM Understood | Because |\n",
        "|------|-----------|----------------|--------|\n",
        "| 2 | \"that INR amount\" | 4,156,000 INR | Saw Turn 1's ToolMessage |\n",
        "| 3 | \"the EMI you calculated\" | Previous EMI value | Saw Turn 2's ToolMessage |\n",
        "\n",
        "**The LLM doesn't \"remember\"‚Äîit sees the ENTIRE history every time!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 5: Second Example - Car Purchase Planning\n",
        "\n",
        "A more realistic multi-turn scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start fresh conversation\n",
        "car_conversation = {\"messages\": []}\n",
        "\n",
        "print(\"SCENARIO: Car Purchase Planning\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 1: Budget conversion\n",
        "print(\"\\nTurn 1\")\n",
        "print(\"-\" * 40)\n",
        "query1 = \"I have a budget of 2000000 INR for a car. What's that in USD?\"\n",
        "print(f\"üë§ User: {query1}\")\n",
        "\n",
        "car_conversation[\"messages\"].append(HumanMessage(content=query1))\n",
        "car_conversation = app.invoke(car_conversation)\n",
        "\n",
        "print(f\"ü§ñ Assistant: {car_conversation['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 2: EMI for full budget\n",
        "print(\"\\nTurn 2\")\n",
        "print(\"-\" * 40)\n",
        "query2 = \"If I take a loan for my full budget at 9% for 5 years, what's my monthly payment?\"\n",
        "print(f\"üë§ User: {query2}\")\n",
        "print(\"   (References 'my full budget' = 2,000,000 INR from Turn 1)\")\n",
        "\n",
        "car_conversation[\"messages\"].append(HumanMessage(content=query2))\n",
        "car_conversation = app.invoke(car_conversation)\n",
        "\n",
        "print(f\"\\nü§ñ Assistant: {car_conversation['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 3: What-if scenario\n",
        "print(\"\\nTurn 3\")\n",
        "print(\"-\" * 40)\n",
        "query3 = \"What if I reduce the tenure to 3 years instead?\"\n",
        "print(f\"üë§ User: {query3}\")\n",
        "print(\"   (References same loan amount and rate, just different tenure)\")\n",
        "\n",
        "car_conversation[\"messages\"].append(HumanMessage(content=query3))\n",
        "car_conversation = app.invoke(car_conversation)\n",
        "\n",
        "print(f\"\\nü§ñ Assistant: {car_conversation['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn 4: Comparison question\n",
        "print(\"\\nTurn 4\")\n",
        "print(\"-\" * 40)\n",
        "query4 = \"How much more would I pay monthly with the 3-year plan compared to 5 years?\"\n",
        "print(f\"üë§ User: {query4}\")\n",
        "print(\"   (Requires comparing results from Turn 2 and Turn 3)\")\n",
        "\n",
        "car_conversation[\"messages\"].append(HumanMessage(content=query4))\n",
        "car_conversation = app.invoke(car_conversation)\n",
        "\n",
        "print(f\"\\nü§ñ Assistant: {car_conversation['messages'][-1].content}\")\n",
        "print(f\"\\nüìä Final state size: {len(car_conversation['messages'])} messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 6: Starting a Fresh Conversation\n",
        "\n",
        "To reset context, simply create a new state object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New conversation (no context from previous)\n",
        "fresh_conversation = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 500 EUR to GBP\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result_fresh = app.invoke(fresh_conversation)\n",
        "\n",
        "print(\"FRESH CONVERSATION (New State)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Messages in state: {len(result_fresh['messages'])}\")\n",
        "print(f\"\\nü§ñ Response: {result_fresh['messages'][-1].content}\")\n",
        "print(\"\\n‚úÖ No context from previous car purchase conversation!\")\n",
        "print(\"   (It doesn't know about 2,000,000 INR or any EMI calculations)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Fresh vs Continued Conversations\n",
        "\n",
        "```python\n",
        "# CONTINUE existing conversation:\n",
        "state[\"messages\"].append(HumanMessage(\"Next question\"))\n",
        "state = app.invoke(state)  # Sees ALL previous messages\n",
        "\n",
        "# START fresh conversation:\n",
        "new_state = {\"messages\": [HumanMessage(\"First question\")]}\n",
        "new_state = app.invoke(new_state)  # No previous context\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 7: Context-Aware Behavior Analysis\n",
        "\n",
        "### Reference Point: What the LLM Can Do With Context\n",
        "\n",
        "| Capability | Example | How It Works |\n",
        "|------------|---------|-------------|\n",
        "| **Reference values** | \"that amount\" | Finds value in previous ToolMessage |\n",
        "| **Recall calculations** | \"what was the EMI?\" | Reads from conversation history |\n",
        "| **Modify parameters** | \"change tenure to 3 years\" | Keeps other params, updates one |\n",
        "| **Compare results** | \"difference between plans\" | Analyzes multiple past tool outputs |\n",
        "| **Understand pronouns** | \"my budget\", \"the loan\" | Context from earlier turns |\n",
        "\n",
        "### What the LLM Cannot Do\n",
        "\n",
        "| Limitation | Example | Why |\n",
        "|------------|---------|-----|\n",
        "| Cross-session memory | \"Remember last week's calculation\" | State resets each session |\n",
        "| Infinite context | Very long conversations | Token limits apply |\n",
        "| External memory | \"Save this for later\" | No persistent storage by default |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 8: Visualize State Growth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"STATE GROWTH VISUALIZATION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nCar Purchase Conversation:\")\n",
        "print()\n",
        "\n",
        "# Count messages by type\n",
        "human_count = sum(1 for m in car_conversation[\"messages\"] if isinstance(m, HumanMessage))\n",
        "ai_count = sum(1 for m in car_conversation[\"messages\"] if isinstance(m, AIMessage))\n",
        "tool_count = sum(1 for m in car_conversation[\"messages\"] if isinstance(m, ToolMessage))\n",
        "\n",
        "print(f\"  üë§ HumanMessages:  {human_count}\")\n",
        "print(f\"  ü§ñ AIMessages:     {ai_count}\")\n",
        "print(f\"  üîß ToolMessages:   {tool_count}\")\n",
        "print(f\"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
        "print(f\"  üìä Total:          {len(car_conversation['messages'])}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"State growth per turn:\")\n",
        "print(\"  Turn 1: +1 Human, +2 AI (tool call + response), +1 Tool = 4 messages\")\n",
        "print(\"  Turn 2: +1 Human, +2 AI, +1 Tool = 4 messages (total: 8)\")\n",
        "print(\"  Turn 3: +1 Human, +2 AI, +1 Tool = 4 messages (total: 12)\")\n",
        "print(\"  Turn 4: +1 Human, +1 AI (no tool needed) = 2 messages (total: 14)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "| Concept | Key Takeaway |\n",
        "|---------|-------------|\n",
        "| **State Persistence** | Same state object = continued conversation |\n",
        "| **Message Accumulation** | State grows with each turn, never shrinks |\n",
        "| **Context Awareness** | LLM sees FULL history every invocation |\n",
        "| **Reference Resolution** | \"that amount\", \"my budget\" resolved from history |\n",
        "| **Fresh Conversations** | New state object = clean slate |\n",
        "\n",
        "## Multi-Turn Conversation Pattern\n",
        "\n",
        "```python\n",
        "# Initialize\n",
        "state = {\"messages\": []}\n",
        "\n",
        "# Turn N (repeat for each turn)\n",
        "state[\"messages\"].append(HumanMessage(content=\"User query\"))\n",
        "state = app.invoke(state)\n",
        "response = state[\"messages\"][-1].content\n",
        "```\n",
        "\n",
        "## Context Capabilities Checklist\n",
        "\n",
        "```\n",
        "‚úÖ Reference previous values (\"that amount\")\n",
        "‚úÖ Recall past calculations (\"what was the EMI?\")\n",
        "‚úÖ Modify parameters (\"change to 3 years\")\n",
        "‚úÖ Compare results across turns\n",
        "‚úÖ Understand pronouns and references\n",
        "‚ùå Cross-session memory (resets each session)\n",
        "‚ùå Infinite context (token limits apply)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ LangGraph Tutorial Series Complete!\n",
        "\n",
        "### What You've Learned\n",
        "\n",
        "| Notebook | Topic | Key Concept |\n",
        "|----------|-------|-------------|\n",
        "| 01 | Setup & Validation | Environment, LLM initialization |\n",
        "| 02 | Getting Started with Tools | @tool decorator, schemas |\n",
        "| 03 | Currency Converter | Multi-parameter tools |\n",
        "| 04 | EMI Calculator | Complex calculations, edge cases |\n",
        "| 05 | Graph Construction | StateGraph, nodes, edges, ToolNode |\n",
        "| 06 | Single Tool Execution | Basic agent ‚Üí tool ‚Üí response |\n",
        "| 07 | Parallel Execution | Multiple independent tools |\n",
        "| 08 | Sequential Execution | Dependent tool chains |\n",
        "| 09 | Conversational Context | Multi-turn conversations |\n",
        "\n",
        "### Core Principles Mastered\n",
        "\n",
        "- üîß **Tools** extend LLM capabilities with real-world actions\n",
        "- üìä **State** enables conversation memory and context\n",
        "- üîÄ **Routing** creates dynamic, conditional behavior\n",
        "- üîÑ **Cycles** allow iterative reasoning and tool chains\n",
        "- ü§ñ **LLM Autonomy** - the model orchestrates everything\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Build custom tools for your specific domain\n",
        "- Add human-in-the-loop workflows\n",
        "- Implement sub-graphs for complex tasks\n",
        "- Integrate LangSmith for observability\n",
        "- Deploy in production applications\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
