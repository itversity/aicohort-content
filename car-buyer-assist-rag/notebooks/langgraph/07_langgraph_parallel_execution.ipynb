{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Tutorial: Parallel Execution\n",
        "\n",
        "## Objective\n",
        "Understand how the agent executes multiple independent tools simultaneously in a single request.\n",
        "\n",
        "## What You'll Learn\n",
        "1. When parallel execution occurs (independent tasks)\n",
        "2. How the LLM requests multiple tools in one AIMessage\n",
        "3. How ToolNode executes tools concurrently\n",
        "4. The message pattern for parallel execution (5 messages)\n",
        "5. Performance benefits of parallel tool calls\n",
        "\n",
        "## Prerequisites\n",
        "- Completed: Notebook 06 (Single Tool Execution)\n",
        "- Understanding of the 4-message single tool pattern\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: The Parallel Execution Pattern\n",
        "\n",
        "### When Does Parallel Execution Happen?\n",
        "\n",
        "Parallel execution occurs when:\n",
        "- Query requires **multiple tools**\n",
        "- Tasks are **independent** (neither needs the other's result)\n",
        "- LLM recognizes this and calls all tools at once\n",
        "\n",
        "### Reference Point: Parallel vs Sequential\n",
        "\n",
        "| Pattern | Condition | Example |\n",
        "|---------|-----------|--------|\n",
        "| **Parallel** | Tasks are independent | \"Convert USD to EUR AND calculate EMI\" |\n",
        "| **Sequential** | Task B needs Task A's result | \"Convert my loan to EUR, then calculate EMI\" |\n",
        "\n",
        "### Execution Flow\n",
        "\n",
        "```\n",
        "Query: Task A AND Task B (independent)\n",
        "  â†“\n",
        "Agent: Analyzes query, sees two independent tasks\n",
        "  â†“\n",
        "Agent: Returns AIMessage with tool_calls=[Tool A, Tool B]\n",
        "  â†“\n",
        "ToolNode: Executes BOTH tools simultaneously (ThreadPoolExecutor)\n",
        "  â†“\n",
        "Agent: Receives both results, synthesizes single response\n",
        "  â†“\n",
        "END\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Message Pattern Comparison\n",
        "\n",
        "| Execution Type | Message Count | Pattern |\n",
        "|----------------|---------------|--------|\n",
        "| **Single Tool** | 4 messages | Human â†’ AI(1 tool) â†’ Tool â†’ AI |\n",
        "| **Parallel (2 tools)** | 5 messages | Human â†’ AI(2 tools) â†’ Tool â†’ Tool â†’ AI |\n",
        "| **Parallel (3 tools)** | 6 messages | Human â†’ AI(3 tools) â†’ Tool â†’ Tool â†’ Tool â†’ AI |\n",
        "\n",
        "**Formula:** `messages = 3 + number_of_tools`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 2: Setup\n",
        "\n",
        "Build the financial assistant graph with both tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"âœ… Environment loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools\n",
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates or to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \"\"\"\n",
        "    if principal <= 0 or annual_interest_rate < 0 or tenure_months <= 0:\n",
        "        return \"Error: Invalid input parameters\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"âœ… Tools defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM and build graph\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "tools = [currency_converter, emi_calculator]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"Agent node: Calls LLM with current messages.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router: Check if agent wants to use tools.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# Build graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"agent\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"âœ… Graph compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 3: Parallel Execution Example\n",
        "\n",
        "**Query:** \"Convert 100000 USD to EUR AND ALSO calculate EMI for 500000 INR at 8.5% for 60 months\"\n",
        "\n",
        "### Why This Query Triggers Parallel Execution\n",
        "\n",
        "| Task | Tool Needed | Depends On Other? |\n",
        "|------|-------------|-------------------|\n",
        "| Convert 100000 USD to EUR | currency_converter | âŒ No |\n",
        "| Calculate EMI for 500000 INR | emi_calculator | âŒ No |\n",
        "\n",
        "**Result:** Tasks are independent â†’ Parallel execution!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create state with parallel query\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 100000 USD to EUR AND ALSO calculate EMI for 500000 INR at 8.5% for 60 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query Analysis:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Query: {state['messages'][0].content}\")\n",
        "print(\"\\nExpected behavior:\")\n",
        "print(\"  â€¢ LLM should identify TWO independent tasks\")\n",
        "print(\"  â€¢ LLM should call BOTH tools in a single request\")\n",
        "print(\"  â€¢ ToolNode should execute them in parallel\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the graph\n",
        "result = app.invoke(state)\n",
        "\n",
        "print(\"Execution Complete!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total messages: {len(result['messages'])} (expected: 5 for parallel)\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 4: Verify Parallel Tool Calls\n",
        "\n",
        "The key indicator of parallel execution: **multiple tool_calls in a single AIMessage**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the AIMessage that contains tool calls\n",
        "tool_call_message = result['messages'][1]\n",
        "\n",
        "print(\"PARALLEL EXECUTION VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Message type: {type(tool_call_message).__name__}\")\n",
        "print(f\"Number of tool_calls: {len(tool_call_message.tool_calls)}\")\n",
        "\n",
        "if len(tool_call_message.tool_calls) > 1:\n",
        "    print(\"\\nðŸš€ CONFIRMED: Parallel execution detected!\")\n",
        "    print(f\"   {len(tool_call_message.tool_calls)} tools called in a SINGLE AIMessage\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  Single tool call detected (not parallel)\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Tool Calls Detail:\")\n",
        "print(\"-\" * 80)\n",
        "for i, tc in enumerate(tool_call_message.tool_calls, 1):\n",
        "    print(f\"\\n  Tool Call {i}:\")\n",
        "    print(f\"    Name: {tc['name']}\")\n",
        "    print(f\"    Args: {tc['args']}\")\n",
        "    print(f\"    ID:   {tc['id']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Single AIMessage with Multiple tool_calls\n",
        "\n",
        "```python\n",
        "# Parallel execution signature:\n",
        "AIMessage(\n",
        "    content=\"\",\n",
        "    tool_calls=[\n",
        "        {\"name\": \"currency_converter\", \"args\": {...}, \"id\": \"call_1\"},\n",
        "        {\"name\": \"emi_calculator\", \"args\": {...}, \"id\": \"call_2\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# vs Sequential execution (separate messages):\n",
        "AIMessage(tool_calls=[{\"name\": \"tool_1\", ...}])  # First call\n",
        "# ... tool executes ...\n",
        "AIMessage(tool_calls=[{\"name\": \"tool_2\", ...}])  # Second call (needs first result)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 5: Examine the Complete Message Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"COMPLETE MESSAGE FLOW\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    print(f\"\\n{'â”€' * 80}\")\n",
        "    print(f\"MESSAGE {i}: {type(msg).__name__}\")\n",
        "    print(f\"{'â”€' * 80}\")\n",
        "    \n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"  ðŸ‘¤ USER INPUT\")\n",
        "        print(f\"  Content: {msg.content[:60]}...\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"  ðŸ¤– AGENT: Requesting {len(msg.tool_calls)} tool(s) IN PARALLEL\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"    â€¢ {tc['name']}\")\n",
        "        else:\n",
        "            print(f\"  ðŸ¤– AGENT: Final synthesized response\")\n",
        "            print(f\"  Content: {msg.content[:100]}...\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        # Find which tool this result belongs to\n",
        "        tool_name = \"unknown\"\n",
        "        for tc in tool_call_message.tool_calls:\n",
        "            if tc['id'] == msg.tool_call_id:\n",
        "                tool_name = tc['name']\n",
        "                break\n",
        "        print(f\"  ðŸ”§ TOOL RESULT: {tool_name}\")\n",
        "        print(f\"  Tool Call ID: {msg.tool_call_id}\")\n",
        "        # Show first line of result\n",
        "        first_line = msg.content.split('\\n')[0]\n",
        "        print(f\"  Result: {first_line}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Parallel Execution Message Sequence\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ MESSAGE 1: HumanMessage                                                â”‚\n",
        "â”‚   \"Convert 100000 USD to EUR AND calculate EMI for 500000 INR...\"     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                    â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ MESSAGE 2: AIMessage (with 2 tool_calls)                               â”‚\n",
        "â”‚   tool_calls = [                                                       â”‚\n",
        "â”‚     {name: \"currency_converter\", args: {...}},  â†â”€â”€ Both tools        â”‚\n",
        "â”‚     {name: \"emi_calculator\", args: {...}}       â†â”€â”€ in ONE message    â”‚\n",
        "â”‚   ]                                                                    â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                    â†“\n",
        "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ToolNode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "              â”‚   Executes BOTH in parallel    â”‚\n",
        "              â”‚   using ThreadPoolExecutor     â”‚\n",
        "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                        â†“             â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ MESSAGE 3: ToolMessage      â”‚ â”‚ MESSAGE 4: ToolMessage      â”‚\n",
        "â”‚   currency_converter result â”‚ â”‚   emi_calculator result     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                        â†“             â†“\n",
        "                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
        "                               â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ MESSAGE 5: AIMessage (final response)                                  â”‚\n",
        "â”‚   Synthesizes BOTH results into a single natural language answer       â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 6: Deep Dive into Each Message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 1: User Query\n",
        "print(\"MESSAGE 1: HumanMessage (User Query)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Content: {result['messages'][0].content}\")\n",
        "print(\"\\nâ†’ User asks for TWO independent things in one query.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 2: AIMessage with MULTIPLE tool_calls\n",
        "print(\"MESSAGE 2: AIMessage (Parallel Tool Requests)\")\n",
        "print(\"=\" * 80)\n",
        "msg2 = result['messages'][1]\n",
        "print(f\"Number of tool_calls: {len(msg2.tool_calls)}\")\n",
        "print(f\"\\nTool Calls:\")\n",
        "for i, tc in enumerate(msg2.tool_calls, 1):\n",
        "    print(f\"\\n  [{i}] {tc['name']}\")\n",
        "    print(f\"      Args: {tc['args']}\")\n",
        "\n",
        "print(\"\\nâ†’ LLM recognized TWO independent tasks.\")\n",
        "print(\"â†’ Requested BOTH tools in a SINGLE AIMessage.\")\n",
        "print(\"â†’ This triggers parallel execution in ToolNode.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Messages 3 & 4: Tool Results (executed in parallel)\n",
        "print(\"MESSAGES 3 & 4: ToolMessages (Parallel Results)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for idx in [2, 3]:\n",
        "    msg = result['messages'][idx]\n",
        "    print(f\"\\nMessage {idx + 1}: ToolMessage\")\n",
        "    print(f\"  Tool Call ID: {msg.tool_call_id}\")\n",
        "    print(f\"  Result:\")\n",
        "    for line in msg.content.split('\\n'):\n",
        "        print(f\"    {line}\")\n",
        "\n",
        "print(\"\\nâ†’ Both tools executed simultaneously by ToolNode.\")\n",
        "print(\"â†’ Each result has its own ToolMessage.\")\n",
        "print(\"â†’ tool_call_id links result to original request.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 5: Final Synthesized Response\n",
        "print(\"MESSAGE 5: AIMessage (Synthesized Response)\")\n",
        "print(\"=\" * 80)\n",
        "msg5 = result['messages'][4]\n",
        "print(f\"Content:\\n{msg5.content}\")\n",
        "\n",
        "print(\"\\nâ†’ LLM received BOTH tool results.\")\n",
        "print(\"â†’ Synthesized into a single coherent response.\")\n",
        "print(\"â†’ No more tool_calls = Execution ends.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 7: Streaming View (Real-Time Execution)\n",
        "\n",
        "Use `.stream()` to see each step as it happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset state and stream execution\n",
        "state_stream = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 100000 USD to EUR AND ALSO calculate EMI for 500000 INR at 8.5% for 60 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"STREAMING EXECUTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Watch each node execute in real-time...\\n\")\n",
        "\n",
        "step_count = 0\n",
        "for event in app.stream(state_stream):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: '{node_name}'\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            for msg in data[\"messages\"]:\n",
        "                if isinstance(msg, AIMessage):\n",
        "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "                        print(f\"  ðŸš€ PARALLEL CALL: {len(msg.tool_calls)} tools requested\")\n",
        "                        for tc in msg.tool_calls:\n",
        "                            print(f\"     â€¢ {tc['name']}\")\n",
        "                    else:\n",
        "                        print(f\"  ðŸ’¬ Final response generated\")\n",
        "                        \n",
        "                elif isinstance(msg, ToolMessage):\n",
        "                    print(f\"  âœ… Tool executed (ID: {msg.tool_call_id[:20]}...)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"Total steps: {step_count}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Streaming Output Analysis\n",
        "\n",
        "```\n",
        "Step 1: agent node\n",
        "  â†’ LLM analyzes query\n",
        "  â†’ Returns AIMessage with 2 tool_calls\n",
        "\n",
        "Step 2: tools node  \n",
        "  â†’ ToolNode receives 2 tool_calls\n",
        "  â†’ Executes BOTH using ThreadPoolExecutor\n",
        "  â†’ Returns 2 ToolMessages\n",
        "\n",
        "Step 3: agent node\n",
        "  â†’ LLM sees both tool results\n",
        "  â†’ Generates final synthesized response\n",
        "  â†’ No more tool_calls â†’ Routes to END\n",
        "```\n",
        "\n",
        "**Key Insight:** Only 3 steps (agent â†’ tools â†’ agent) even with 2 tools!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 8: Performance Benefits\n",
        "\n",
        "### Reference Point: Parallel vs Sequential Performance\n",
        "\n",
        "| Metric | Sequential (2 tools) | Parallel (2 tools) |\n",
        "|--------|---------------------|--------------------|\n",
        "| LLM Calls | 4 | 2 |\n",
        "| Tool Executions | 2 (one at a time) | 2 (simultaneous) |\n",
        "| Loop Iterations | 2 | 1 |\n",
        "| Messages | 6+ | 5 |\n",
        "| Total Time | ~4 seconds | ~2 seconds |\n",
        "\n",
        "### Why Parallel is Faster\n",
        "\n",
        "```\n",
        "Sequential:                      Parallel:\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ LLM #1  â”‚ 500ms               â”‚ LLM #1  â”‚ 500ms\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ Tool A  â”‚ 100ms               â”‚ Tool A  â”‚ â”\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”‚ Tool B  â”‚ â”˜ 100ms (parallel)\n",
        "â”‚ LLM #2  â”‚ 500ms               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”‚ LLM #2  â”‚ 500ms\n",
        "â”‚ Tool B  â”‚ 100ms               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     Total: ~1100ms\n",
        "â”‚ LLM #3  â”‚ 500ms\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ LLM #4  â”‚ 500ms\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "Total: ~2200ms\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 9: How ToolNode Handles Parallel Execution\n",
        "\n",
        "### Reference Point: ToolNode Internal Behavior\n",
        "\n",
        "```python\n",
        "# Simplified ToolNode logic:\n",
        "def __call__(self, state):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    tool_calls = last_message.tool_calls\n",
        "    \n",
        "    if len(tool_calls) == 1:\n",
        "        # Single tool: execute directly\n",
        "        result = execute_tool(tool_calls[0])\n",
        "        return {\"messages\": [result]}\n",
        "    else:\n",
        "        # Multiple tools: execute in parallel\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            results = list(executor.map(execute_tool, tool_calls))\n",
        "        return {\"messages\": results}  # Multiple ToolMessages\n",
        "```\n",
        "\n",
        "### Key Points\n",
        "\n",
        "1. **Automatic Detection:** ToolNode checks `len(tool_calls)`\n",
        "2. **ThreadPoolExecutor:** Python's built-in for concurrent execution\n",
        "3. **Result Ordering:** Results maintain order of original tool_calls\n",
        "4. **ID Matching:** Each ToolMessage has `tool_call_id` for correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 10: LLM's Autonomous Decision-Making\n",
        "\n",
        "### How the LLM Decides to Use Parallel Execution\n",
        "\n",
        "The LLM determines independence by analyzing:\n",
        "\n",
        "| Signal | Example | Interpretation |\n",
        "|--------|---------|---------------|\n",
        "| \"AND\" / \"ALSO\" | \"Convert X AND calculate Y\" | Likely independent |\n",
        "| \"both\" | \"Do both tasks\" | Likely independent |\n",
        "| \"then\" / \"after\" | \"Convert, then calculate with result\" | Dependent (sequential) |\n",
        "| Data flow | \"Convert $X, then calculate EMI for that amount\" | Dependent (sequential) |\n",
        "\n",
        "### No Hardcoded Logic\n",
        "\n",
        "```\n",
        "You define:           LLM decides:\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "â€¢ Tool schemas       â€¢ Are tasks independent?\n",
        "â€¢ Graph structure    â€¢ How many tools to call?\n",
        "â€¢ Router logic       â€¢ What parameters to extract?\n",
        "                     â€¢ When to stop?\n",
        "```\n",
        "\n",
        "> **Key Insight:** The same query structure can produce parallel or sequential execution depending on semantic analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "| Concept | Key Takeaway |\n",
        "|---------|-------------|\n",
        "| **When Parallel Occurs** | Tasks are independent (neither needs other's result) |\n",
        "| **How to Identify** | Single AIMessage with multiple `tool_calls` |\n",
        "| **Message Count** | 3 + number_of_tools (5 for 2 tools) |\n",
        "| **Execution** | ToolNode uses ThreadPoolExecutor |\n",
        "| **Performance** | Fewer LLM calls, faster execution |\n",
        "| **LLM Autonomy** | Decides independence from natural language |\n",
        "\n",
        "## Parallel Execution Checklist\n",
        "\n",
        "```\n",
        "âœ… Multiple tool_calls in ONE AIMessage\n",
        "âœ… Tools execute simultaneously\n",
        "âœ… Multiple ToolMessages returned\n",
        "âœ… Single synthesized final response\n",
        "âœ… Only 2 LLM calls (regardless of tool count)\n",
        "âœ… Only 1 loop iteration (agent â†’ tools â†’ agent â†’ END)\n",
        "```\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "In **Notebook 08: Sequential Execution**, we'll explore:\n",
        "- Dependent tasks where Task B needs Task A's result\n",
        "- Multiple loop iterations\n",
        "- How the LLM chains tool calls\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
