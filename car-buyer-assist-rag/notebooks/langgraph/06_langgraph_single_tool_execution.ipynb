{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Tutorial: Single Tool Execution\n",
        "\n",
        "## Objective\n",
        "Understand the fundamental execution pattern when an agent uses a single tool to answer a query.\n",
        "\n",
        "## What You'll Learn\n",
        "1. The complete execution flow: START â†’ Agent â†’ Tools â†’ Agent â†’ END\n",
        "2. How messages accumulate in state during execution\n",
        "3. The two LLM calls pattern (decide + respond)\n",
        "4. Message types and their roles (HumanMessage, AIMessage, ToolMessage)\n",
        "5. How the router determines flow based on `tool_calls`\n",
        "\n",
        "## Prerequisites\n",
        "- Completed: Notebook 05 (Graph Construction)\n",
        "- Understanding of the agent-tools-loop architecture\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: The Single Tool Pattern\n",
        "\n",
        "### Execution Flow\n",
        "\n",
        "```\n",
        "User Query â†’ Agent analyzes â†’ Calls ONE tool â†’ Tool executes â†’ Agent responds\n",
        "```\n",
        "\n",
        "### Reference Point: What Happens Step by Step\n",
        "\n",
        "| Step | Node | Action | Output |\n",
        "|------|------|--------|--------|\n",
        "| 1 | START | Entry point | Route to agent |\n",
        "| 2 | agent | LLM decides to call tool | AIMessage with `tool_calls` |\n",
        "| 3 | router | Sees `tool_calls` | Route to tools |\n",
        "| 4 | tools | Executes tool function | ToolMessage with result |\n",
        "| 5 | agent | LLM formulates answer | AIMessage with `content` |\n",
        "| 6 | router | No `tool_calls` | Route to END |\n",
        "\n",
        "### Message Count Pattern\n",
        "\n",
        "```\n",
        "Single tool execution always produces 4 messages:\n",
        "  1. HumanMessage     (user query)\n",
        "  2. AIMessage        (tool call request)\n",
        "  3. ToolMessage      (tool result)\n",
        "  4. AIMessage        (final response)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 2: Setup\n",
        "\n",
        "Rebuild the graph from Notebook 05."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"âœ… Environment loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools\n",
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \n",
        "    Args:\n",
        "        amount: The amount to convert\n",
        "        from_currency: Source currency code (USD, EUR, GBP, INR, JPY)\n",
        "        to_currency: Target currency code (USD, EUR, GBP, INR, JPY)\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates or to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \n",
        "    Args:\n",
        "        principal: The loan amount\n",
        "        annual_interest_rate: Annual interest rate as percentage\n",
        "        tenure_months: Loan tenure in months\n",
        "        currency: Currency code for display\n",
        "    \"\"\"\n",
        "    if principal <= 0 or annual_interest_rate < 0 or tenure_months <= 0:\n",
        "        return \"Error: Invalid input parameters\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"âœ… Tools defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM with tools\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "tools = [currency_converter, emi_calculator]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(\"âœ… LLM initialized with tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build graph\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"Agent node that invokes the LLM.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router that decides next step based on tool_calls.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# Assemble the graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"agent\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"âœ… Graph compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 3: Execute a Single Tool Query\n",
        "\n",
        "**Query:** \"What is 1000 USD in EUR?\"\n",
        "\n",
        "This query requires exactly ONE tool call (currency_converter)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial state with user query\n",
        "state = {\n",
        "    \"messages\": [HumanMessage(content=\"What is 1000 USD in EUR?\")]\n",
        "}\n",
        "\n",
        "print(\"Initial State:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Query: {state['messages'][0].content}\")\n",
        "print(f\"Message count: {len(state['messages'])}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the graph\n",
        "result = app.invoke(state)\n",
        "\n",
        "print(\"Execution Complete!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Final message count: {len(result['messages'])}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 4: Examine the Message Flow\n",
        "\n",
        "Let's inspect each message to understand what happened at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"MESSAGE FLOW ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    print(f\"\\n{'â”€' * 70}\")\n",
        "    print(f\"MESSAGE {i}: {type(msg).__name__}\")\n",
        "    print(f\"{'â”€' * 70}\")\n",
        "    \n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"  ðŸ‘¤ USER INPUT\")\n",
        "        print(f\"  Content: {msg.content}\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"  ðŸ¤– AGENT DECISION: Call tool(s)\")\n",
        "            print(f\"  Tool Calls: {len(msg.tool_calls)}\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"    â€¢ Tool: {tc['name']}\")\n",
        "                print(f\"      Args: {tc['args']}\")\n",
        "                print(f\"      ID: {tc['id']}\")\n",
        "        else:\n",
        "            print(f\"  ðŸ¤– AGENT RESPONSE: Final answer\")\n",
        "            print(f\"  Content: {msg.content}\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"  ðŸ”§ TOOL RESULT\")\n",
        "        print(f\"  Tool Call ID: {msg.tool_call_id}\")\n",
        "        print(f\"  Content:\\n{msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: Message Anatomy\n",
        "\n",
        "| Message Type | Key Attributes | Created By |\n",
        "|--------------|----------------|------------|\n",
        "| `HumanMessage` | `.content` | User input |\n",
        "| `AIMessage` (tool call) | `.tool_calls` (list of dicts) | LLM deciding to use tool |\n",
        "| `ToolMessage` | `.content`, `.tool_call_id` | ToolNode executing tool |\n",
        "| `AIMessage` (response) | `.content` | LLM providing final answer |\n",
        "\n",
        "### The `tool_calls` Structure\n",
        "\n",
        "```python\n",
        "msg.tool_calls = [\n",
        "    {\n",
        "        \"name\": \"currency_converter\",      # Which tool to call\n",
        "        \"args\": {                          # Arguments extracted from query\n",
        "            \"amount\": 1000,\n",
        "            \"from_currency\": \"USD\",\n",
        "            \"to_currency\": \"EUR\"\n",
        "        },\n",
        "        \"id\": \"call_abc123\"                # Unique ID for matching response\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 5: Deep Dive into Each Message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 1: HumanMessage (User Query)\n",
        "print(\"MESSAGE 1: HumanMessage\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Type: {type(result['messages'][0]).__name__}\")\n",
        "print(f\"Content: {result['messages'][0].content}\")\n",
        "print(\"\\nâ†’ This is the starting point. User's natural language query.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 2: AIMessage with tool_calls (Agent's Decision)\n",
        "print(\"MESSAGE 2: AIMessage (Tool Call Request)\")\n",
        "print(\"=\" * 70)\n",
        "msg2 = result['messages'][1]\n",
        "print(f\"Type: {type(msg2).__name__}\")\n",
        "print(f\"Has tool_calls: {bool(msg2.tool_calls)}\")\n",
        "print(f\"\\nTool Calls Detail:\")\n",
        "print(msg2.tool_calls)\n",
        "print(\"\\nâ†’ LLM analyzed query and decided to call 'currency_converter'.\")\n",
        "print(\"â†’ LLM extracted parameters from natural language.\")\n",
        "print(\"â†’ LLM did NOT execute the toolâ€”just requested it.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 3: ToolMessage (Tool Execution Result)\n",
        "print(\"MESSAGE 3: ToolMessage\")\n",
        "print(\"=\" * 70)\n",
        "msg3 = result['messages'][2]\n",
        "print(f\"Type: {type(msg3).__name__}\")\n",
        "print(f\"Tool Call ID: {msg3.tool_call_id}\")\n",
        "print(f\"\\nContent (Tool Output):\")\n",
        "print(msg3.content)\n",
        "print(\"\\nâ†’ ToolNode executed: currency_converter.invoke({args})\")\n",
        "print(\"â†’ Result stored in ToolMessage for LLM to see.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 4: AIMessage (Final Response)\n",
        "print(\"MESSAGE 4: AIMessage (Final Response)\")\n",
        "print(\"=\" * 70)\n",
        "msg4 = result['messages'][3]\n",
        "print(f\"Type: {type(msg4).__name__}\")\n",
        "print(f\"Has tool_calls: {bool(msg4.tool_calls) if hasattr(msg4, 'tool_calls') else False}\")\n",
        "print(f\"\\nContent:\")\n",
        "print(msg4.content)\n",
        "print(\"\\nâ†’ LLM saw the tool result and formulated a natural language answer.\")\n",
        "print(\"â†’ No more tool_calls = Router sends to END.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: The Two LLM Calls\n",
        "\n",
        "Single tool execution involves **exactly 2 LLM calls**:\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ LLM CALL 1: \"What should I do with this query?\"                    â”‚\n",
        "â”‚   Input:  [HumanMessage(\"What is 1000 USD in EUR?\")]               â”‚\n",
        "â”‚   Output: AIMessage(tool_calls=[{currency_converter, args}])       â”‚\n",
        "â”‚   Decision: \"I need to call currency_converter\"                    â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                              â†“\n",
        "            [ToolNode executes currency_converter]\n",
        "                              â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ LLM CALL 2: \"Now I have the result. What should I tell the user?\" â”‚\n",
        "â”‚   Input:  [HumanMessage, AIMessage(tool_calls), ToolMessage]       â”‚\n",
        "â”‚   Output: AIMessage(content=\"1000 USD equals 920 EUR...\")          â”‚\n",
        "â”‚   Decision: \"I have enough info. Here's my answer.\"                â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 6: Visualize the Conversation Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"CONVERSATION FLOW VISUALIZATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"\\n[{i}] ðŸ‘¤ USER:\")\n",
        "        print(f\"    \\\"{msg.content}\\\"\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT â†’ Calling tool:\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"    Tool: {tc['name']}\")\n",
        "                print(f\"    Args: {tc['args']}\")\n",
        "        else:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT â†’ Final response:\")\n",
        "            print(f\"    \\\"{msg.content}\\\"\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"\\n[{i}] ðŸ”§ TOOL RESULT:\")\n",
        "        # Indent each line of the tool output\n",
        "        for line in msg.content.split('\\n'):\n",
        "            print(f\"    {line}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 7: Test with EMI Calculator\n",
        "\n",
        "Let's verify the same pattern with a different tool.\n",
        "\n",
        "**Query:** \"Calculate EMI for a 50000 USD loan at 7.5% for 36 months\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create new state with EMI query\n",
        "state2 = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Calculate EMI for a 50000 USD loan at 7.5% for 36 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query: Calculate EMI for a 50000 USD loan at 7.5% for 36 months\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute\n",
        "result2 = app.invoke(state2)\n",
        "\n",
        "print(f\"\\nâœ… Execution complete\")\n",
        "print(f\"Message count: {len(result2['messages'])} (expected: 4)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the tool called\n",
        "print(\"Tool Selection Verification:\")\n",
        "print(\"=\" * 70)\n",
        "tool_call_msg = result2['messages'][1]\n",
        "if tool_call_msg.tool_calls:\n",
        "    tc = tool_call_msg.tool_calls[0]\n",
        "    print(f\"âœ… LLM selected: {tc['name']}\")\n",
        "    print(f\"\\nExtracted parameters:\")\n",
        "    for key, value in tc['args'].items():\n",
        "        print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the conversation flow\n",
        "print(\"\\nCONVERSATION FLOW:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result2[\"messages\"], 1):\n",
        "    msg_type = type(msg).__name__\n",
        "    \n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"\\n[{i}] ðŸ‘¤ USER: \\\"{msg.content[:50]}...\\\"\")\n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT: Calling {msg.tool_calls[0]['name']}\")\n",
        "        else:\n",
        "            preview = msg.content[:80] + \"...\" if len(msg.content) > 80 else msg.content\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT: \\\"{preview}\\\"\")\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"\\n[{i}] ðŸ”§ TOOL: Executed emi_calculator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show final response\n",
        "print(\"FINAL RESPONSE:\")\n",
        "print(\"=\" * 70)\n",
        "print(result2[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 8: Key Observations\n",
        "\n",
        "### Reference Point: Single Tool Execution Pattern\n",
        "\n",
        "| Aspect | Observation |\n",
        "|--------|-------------|\n",
        "| **LLM Calls** | Exactly 2 (decide + respond) |\n",
        "| **Messages** | Exactly 4 (Human â†’ AI+tools â†’ Tool â†’ AI) |\n",
        "| **Loop Iterations** | 1 (agent â†’ tools â†’ agent â†’ END) |\n",
        "| **Tool Selection** | LLM chooses based on docstring match |\n",
        "| **Parameter Extraction** | LLM parses natural language to typed args |\n",
        "\n",
        "### What the LLM Does Autonomously\n",
        "\n",
        "âœ… **Identifies correct tool** from docstring descriptions  \n",
        "âœ… **Extracts parameters** from natural language query  \n",
        "âœ… **Decides when to stop** (no more tools needed)  \n",
        "âœ… **Formulates response** using tool output  \n",
        "\n",
        "### What You Define (Not the LLM)\n",
        "\n",
        "âœ… Tool functions with clear docstrings  \n",
        "âœ… Graph structure (nodes + edges)  \n",
        "âœ… Router logic (check for tool_calls)  \n",
        "\n",
        "> **Key Insight:** No hardcoded \"if currency question â†’ call currency_converter\" logic. The LLM orchestrates tool selection based on semantic understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Point: State Evolution\n",
        "\n",
        "```\n",
        "START:       [HumanMessage]                          â†’ 1 message\n",
        "After agent: [HumanMessage, AIMessage(tool_calls)]   â†’ 2 messages  \n",
        "After tools: [HumanMessage, AIMessage, ToolMessage]  â†’ 3 messages\n",
        "After agent: [HumanMessage, AIMessage, ToolMessage, AIMessage] â†’ 4 messages\n",
        "END:         Final state preserved\n",
        "```\n",
        "\n",
        "**State only grows, never shrinks.** This preserves full conversation history for:\n",
        "- Multi-turn conversations\n",
        "- Debugging and tracing\n",
        "- Context for future tool calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "| Concept | Key Takeaway |\n",
        "|---------|-------------|\n",
        "| **Execution Flow** | START â†’ agent â†’ tools â†’ agent â†’ END |\n",
        "| **LLM Calls** | 2 calls: (1) decide tool, (2) generate response |\n",
        "| **Message Types** | Human â†’ AI(tool_calls) â†’ Tool â†’ AI(content) |\n",
        "| **Message Count** | Single tool = 4 messages always |\n",
        "| **LLM Autonomy** | Selects tool, extracts params, decides when done |\n",
        "| **State Growth** | Messages accumulate, never removed |\n",
        "\n",
        "## Critical Understanding\n",
        "\n",
        "```\n",
        "llm_with_tools.invoke() â†’ LLM decides WHAT to call (returns tool_calls)\n",
        "ToolNode â†’ Actually EXECUTES the tool (returns ToolMessage)\n",
        "```\n",
        "\n",
        "The LLM never executes tools directlyâ€”it only requests them!\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "In **Notebook 07: Parallel Execution**, we'll explore what happens when:\n",
        "- Query requires multiple independent tools\n",
        "- LLM calls all tools in a single request\n",
        "- ToolNode executes them simultaneously\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
