{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Tutorial: Building Agentic Workflows with Tool Calling\n",
        "\n",
        "## What You'll Build\n",
        "A financial assistant agent that uses LangGraph to intelligently execute calculations:\n",
        "- Currency conversions (multi-currency support)\n",
        "- EMI (loan payment) calculations\n",
        "- Compound interest computations\n",
        "- Sequential and parallel tool execution\n",
        "\n",
        "## What is LangGraph?\n",
        "LangGraph enables building **stateful, multi-actor applications** with LLMs using **graph-based workflows**. \n",
        "\n",
        "### Why LangGraph vs. Simple LangChain Chains?\n",
        "\n",
        "**Traditional LangChain Chains:**\n",
        "- Linear execution: A â†’ B â†’ C\n",
        "- No cycles or loops\n",
        "- Limited conditional logic\n",
        "- State doesn't persist naturally\n",
        "\n",
        "**LangGraph Advantages:**\n",
        "- âœ… **Cycles**: Loop back for iterative reasoning\n",
        "- âœ… **Conditional Routing**: Dynamic path selection based on LLM decisions\n",
        "- âœ… **State Management**: Persistent conversation context\n",
        "- âœ… **Parallel Execution**: Run independent tools simultaneously\n",
        "- âœ… **Human-in-the-Loop**: Pause for approval (advanced feature)\n",
        "\n",
        "### Real-World Use Cases\n",
        "- Customer support chatbots with tool access (search, ticketing, etc.)\n",
        "- Research agents that browse, summarize, and synthesize information\n",
        "- Financial advisors that fetch data, calculate, and recommend\n",
        "- Code assistants that analyze, execute, and debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives\n",
        "\n",
        "By completing this tutorial, you will:\n",
        "\n",
        "1. **Tool Creation**\n",
        "   - Create custom LangChain tools with proper type hints\n",
        "   - Implement input validation and error handling\n",
        "   - Write comprehensive docstrings for tool discovery\n",
        "\n",
        "2. **Graph Architecture**\n",
        "   - Build a StateGraph with agent and tool nodes\n",
        "   - Configure conditional routing based on LLM decisions\n",
        "   - Understand state management in graph workflows\n",
        "\n",
        "3. **Execution Patterns**\n",
        "   - Execute single tool calls\n",
        "   - Chain multiple sequential tool calls (dependent tasks)\n",
        "   - Trigger parallel tool execution (independent tasks)\n",
        "   - Maintain conversational context across turns\n",
        "\n",
        "4. **Observability**\n",
        "   - Track execution flow through graph nodes\n",
        "   - Monitor tool calls and responses\n",
        "   - Understand the agent's decision-making process\n",
        "\n",
        "## Prerequisites\n",
        "- Basic Python knowledge\n",
        "- Familiarity with LangChain concepts (LLMs, prompts, chains)\n",
        "- Understanding of async/await (helpful but not required)\n",
        "\n",
        "## Estimated Time: 90 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangGraph Architecture Overview\n",
        "\n",
        "### The Agentic Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def render_mermaid(diagram_code, width=400):\n",
        "    '''Helper function to render Mermaid diagrams using mermaid.ink'''\n",
        "    from IPython.display import Image, display\n",
        "    import base64\n",
        "    import urllib.parse\n",
        "    \n",
        "    # Encode diagram for URL\n",
        "    graphbytes = diagram_code.encode('utf-8')\n",
        "    base64_bytes = base64.urlsafe_b64encode(graphbytes)\n",
        "    base64_string = base64_bytes.decode('ascii')\n",
        "    \n",
        "    # Use mermaid.ink service\n",
        "    url = f'https://mermaid.ink/img/{base64_string}'\n",
        "    \n",
        "    # Display as image\n",
        "    display(Image(url=url, width=width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''graph TD\n",
        "    START([START]) --> AGENT[Agent Node: call_llm]\n",
        "    AGENT --> ROUTER{Router: should_continue?}\n",
        "    ROUTER -->|Tool calls present| TOOLS[Tools Node: Execute]\n",
        "    ROUTER -->|No tool calls| END([END])\n",
        "    TOOLS --> AGENT\n",
        "    \n",
        "    style START fill:#90EE90\n",
        "    style END fill:#FFB6C1\n",
        "    style AGENT fill:#87CEEB\n",
        "    style TOOLS fill:#FFD700\n",
        "    style ROUTER fill:#DDA0DD''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Components\n",
        "\n",
        "1. **State**: Shared data structure (list of messages) that flows through nodes\n",
        "2. **Nodes**: Functions that read state, process it, and return updates\n",
        "3. **Edges**: Connections defining flow (conditional or static)\n",
        "4. **Router**: Conditional edge that determines next node based on state\n",
        "\n",
        "### What Makes This \"Agentic\"?\n",
        "\n",
        "The LLM **autonomously decides**:\n",
        "- Which tools to call (if any)\n",
        "- When to call them (sequential vs parallel)\n",
        "- When it has enough information to respond\n",
        "- How many reasoning loops it needs\n",
        "\n",
        "You define the tools and graph structure; the LLM orchestrates execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 2: Environment Setup\n",
        "\n",
        "## Required Environment Variables\n",
        "\n",
        "Create a `.env` file with:\n",
        "\n",
        "```env\n",
        "# GCP Vertex AI Configuration\n",
        "GOOGLE_PROJECT_ID=your-project-id\n",
        "GOOGLE_REGION=us-central1\n",
        "GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json\n",
        "\n",
        "# LangSmith Observability (Optional but Recommended)\n",
        "LANGSMITH_API_KEY=your-langsmith-key\n",
        "LANGSMITH_PROJECT=langgraph-tutorial\n",
        "LANGCHAIN_TRACING_V2=true\n",
        "```\n",
        "\n",
        "### Why These Variables?\n",
        "\n",
        "- **GOOGLE_PROJECT_ID**: GCP project containing Vertex AI resources\n",
        "- **GOOGLE_REGION**: Data residency and latency optimization\n",
        "- **GOOGLE_APPLICATION_CREDENTIALS**: Service account for authentication\n",
        "- **LANGSMITH_***: Enables execution tracing and debugging dashboards\n",
        "\n",
        "### Installation\n",
        "\n",
        "```bash\n",
        "pip install langchain langchain-google-vertexai langgraph python-dotenv\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core LangChain imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# LLM Provider\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Environment management\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Utilities\n",
        "from typing import Literal\n",
        "\n",
        "# For displaying Mermaid diagrams\n",
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv(\"../../.env\")  # Adjust path to your .env location\n",
        "\n",
        "# Verify critical variables are loaded\n",
        "required_vars = [\"GOOGLE_PROJECT_ID\", \"GOOGLE_REGION\"]\n",
        "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
        "\n",
        "if missing_vars:\n",
        "    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
        "\n",
        "print(\"âœ… Environment loaded successfully\")\n",
        "print(f\"   Project: {os.getenv('GOOGLE_PROJECT_ID')}\")\n",
        "print(f\"   Region: {os.getenv('GOOGLE_REGION')}\")\n",
        "print(f\"   LangSmith Tracing: {'Enabled' if os.getenv('LANGCHAIN_TRACING_V2') else 'Disabled'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 3: Tool Creation Fundamentals\n",
        "\n",
        "## Why Create Custom Tools?\n",
        "\n",
        "### LLM Limitations\n",
        "\n",
        "LLMs **cannot** directly perform:\n",
        "- âŒ Real-time calculations (arithmetic, financial formulas)\n",
        "- âŒ External API calls (weather, stock prices, database queries)\n",
        "- âŒ File system operations (read/write files)\n",
        "- âŒ Time-sensitive operations (current date, scheduling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Solution: Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''graph LR\n",
        "    A[LLM Request] --> B{Need Tools?}\n",
        "    B -->|Yes| C[Generate Tool Call]\n",
        "    C --> D[Execute Python Function]\n",
        "    D --> E[Return Result]\n",
        "    E --> F[LLM Synthesizes Response]\n",
        "    B -->|No| F\n",
        "    \n",
        "    style A fill:#87CEEB\n",
        "    style D fill:#FFD700\n",
        "    style F fill:#90EE90''', 1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tools are Python functions that:\n",
        "1. Extend LLM capabilities with executable code\n",
        "2. Have clear schemas (type hints) so LLMs know when to use them\n",
        "3. Return structured results the LLM can incorporate into responses\n",
        "\n",
        "### Tool Decorator Magic\n",
        "\n",
        "The `@tool` decorator:\n",
        "- Auto-generates JSON schema from docstring\n",
        "- Enables LLM to discover tool capabilities\n",
        "- Handles serialization/deserialization\n",
        "- Provides validation and error handling hooks\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "âœ… **DO:**\n",
        "- Write comprehensive docstrings (LLM reads these!)\n",
        "- Use type hints for all parameters\n",
        "- Validate inputs and return clear error messages\n",
        "- Return human-readable strings, not raw data structures\n",
        "\n",
        "âŒ **DON'T:**\n",
        "- Use vague parameter names (\"x\", \"val\", \"data\")\n",
        "- Skip error handling\n",
        "- Return complex objects (LLMs prefer text)\n",
        "- Make assumptions about input formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Args:\n",
        "        amount: The amount to convert\n",
        "        from_currency: Source currency code (USD, EUR, GBP, INR, JPY)\n",
        "        to_currency: Target currency code (USD, EUR, GBP, INR, JPY)\n",
        "    \n",
        "    Returns:\n",
        "        A string with the conversion result including the exchange rate\n",
        "    \"\"\"\n",
        "        \n",
        "    # Simplified exchange rates (relative to USD)\n",
        "    # In production, you would fetch real-time rates from an API\n",
        "    exchange_rates = {\n",
        "        \"USD\": 1.0,\n",
        "        \"EUR\": 0.92,\n",
        "        \"GBP\": 0.79,\n",
        "        \"INR\": 83.12,\n",
        "        \"JPY\": 149.50\n",
        "    }\n",
        "    \n",
        "    # Validate currencies\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency {from_currency}. Supported: {', '.join(exchange_rates.keys())}\"\n",
        "    \n",
        "    if to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency {to_currency}. Supported: {', '.join(exchange_rates.keys())}\"\n",
        "    \n",
        "    # Convert to USD first, then to target currency\n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    \n",
        "    # Calculate the effective exchange rate\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    result = (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(currency_converter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the tool directly (before integrating with graph)\n",
        "print(\"=\" * 70)\n",
        "print(\"TESTING: Currency Converter\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test Case 1: Standard conversion\n",
        "print(\"\\n[Test 1] Convert 1000 USD to EUR\")\n",
        "result = currency_converter.invoke({\"amount\": 1000, \"from_currency\": \"USD\", \"to_currency\": \"EUR\"})\n",
        "print(result)\n",
        "\n",
        "# Test Case 2: Error handling - invalid currency\n",
        "print(\"\\n[Test 2] Invalid currency (XYZ)\")\n",
        "result = currency_converter.invoke({\"amount\": 100, \"from_currency\": \"XYZ\", \"to_currency\": \"USD\"})\n",
        "print(result)\n",
        "\n",
        "# Test Case 3: Same currency conversion\n",
        "print(\"\\n[Test 3] Convert INR to INR (edge case)\")\n",
        "result = currency_converter.invoke({\"amount\": 5000, \"from_currency\": \"INR\", \"to_currency\": \"INR\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Args:\n",
        "        principal: The loan amount (principal)\n",
        "        annual_interest_rate: Annual interest rate as a percentage (e.g., 8.5 for 8.5%)\n",
        "        tenure_months: Loan tenure in months\n",
        "    \n",
        "    Returns:\n",
        "        A string with the EMI calculation details\n",
        "    \"\"\"\n",
        "\n",
        "    # Validate inputs\n",
        "    if principal <= 0:\n",
        "        return \"Error: Principal must be greater than 0\"\n",
        "    if annual_interest_rate < 0:\n",
        "        return \"Error: Interest rate cannot be negative\"\n",
        "    if tenure_months <= 0:\n",
        "        return \"Error: Tenure must be greater than 0\"\n",
        "    \n",
        "    # Calculate monthly interest rate\n",
        "    monthly_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    # Calculate EMI using the formula\n",
        "    if monthly_rate == 0:\n",
        "        # If interest rate is 0, EMI is simply principal divided by tenure\n",
        "        emi = principal / tenure_months\n",
        "    else:\n",
        "        # Standard EMI formula: EMI = P Ã— r Ã— (1 + r)^n / ((1 + r)^n - 1)\n",
        "        emi = principal * monthly_rate * (1 + monthly_rate) ** tenure_months / \\\n",
        "              ((1 + monthly_rate) ** tenure_months - 1)\n",
        "    \n",
        "    # Calculate total payment and total interest\n",
        "    total_payment = emi * tenure_months\n",
        "    total_interest = total_payment - principal\n",
        "    \n",
        "    # Format the result\n",
        "    result = (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Principal: {currency} {principal:,.2f}\\n\"\n",
        "        f\"  Annual Interest Rate: {annual_interest_rate}%\\n\"\n",
        "        f\"  Tenure: {tenure_months} months ({tenure_months//12} years {tenure_months%12} months)\\n\"\n",
        "        f\"  ---\\n\"\n",
        "        f\"  Monthly EMI: {currency} {emi:,.2f}\\n\"\n",
        "        f\"  Total Payment: {currency} {total_payment:,.2f}\\n\"\n",
        "        f\"  Total Interest: {currency} {total_interest:,.2f}\"\n",
        "    )\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(emi_calculator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the EMI calculator\n",
        "print(\"=\" * 70)\n",
        "print(\"TESTING: EMI Calculator\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test Case 1: Standard home loan scenario\n",
        "print(\"\\n[Test 1] Home Loan: â‚¹50L at 8.5% for 5 years\")\n",
        "result = emi_calculator.invoke({\"principal\": 500000, \"annual_interest_rate\": 8.5, \"tenure_months\": 60, \"currency\": \"INR\"})\n",
        "print(result)\n",
        "\n",
        "# Test Case 2: Car loan scenario\n",
        "print(\"\\n[Test 2] Car Loan: â‚¹8L at 9% for 3 years\")\n",
        "result = emi_calculator.invoke({\"principal\": 800000, \"annual_interest_rate\": 9, \"tenure_months\": 36, \"currency\": \"INR\"})\n",
        "print(result)\n",
        "\n",
        "# Test Case 3: Zero interest (edge case)\n",
        "print(\"\\n[Test 3] Zero Interest Loan\")\n",
        "result = emi_calculator.invoke({\"principal\": 100000, \"annual_interest_rate\": 0, \"tenure_months\": 12, \"currency\": \"INR\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Checkpoint 1: Verify Tools Work\n",
        "\n",
        "Before proceeding, ensure:\n",
        "- [ ] Currency converter executes without errors\n",
        "- [ ] EMI calculator produces correct output  \n",
        "- [ ] You understand how `@tool` decorator works\n",
        "- [ ] Error handling catches invalid inputs\n",
        "\n",
        "**What You've Learned:**\n",
        "- Tools extend LLM capabilities with Python code\n",
        "- Type hints + docstrings = automatic schema generation\n",
        "- Return human-readable strings for LLM integration\n",
        "- Input validation prevents runtime errors\n",
        "\n",
        "**Next Step:** Build the LangGraph that lets the LLM decide when to use these tools!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 4: Building the LangGraph\n",
        "\n",
        "## State Management in LangGraph\n",
        "\n",
        "### What is State?\n",
        "\n",
        "State is the **shared data structure** that flows through all nodes in the graph. It acts as:\n",
        "- Memory for the conversation\n",
        "- Container for passing data between nodes\n",
        "- History of all interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''graph LR\n",
        "    A[Initial State] --> B[Node 1: Agent]\n",
        "    B --> C[Updated State]\n",
        "    C --> D[Node 2: Tools]\n",
        "    D --> E[Updated State]\n",
        "    E --> F[Node 3: Agent]\n",
        "    F --> G[Final State]\n",
        "    \n",
        "    style A fill:#90EE90\n",
        "    style C fill:#FFD700\n",
        "    style E fill:#FFD700\n",
        "    style G fill:#FFB6C1''', 1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MessagesState\n",
        "\n",
        "LangGraph provides `MessagesState` which contains:\n",
        "- `messages`: List of all conversation messages\n",
        "\n",
        "### Message Types\n",
        "\n",
        "1. **HumanMessage**: User input\n",
        "   ```python\n",
        "   HumanMessage(content=\"Convert 100 USD to EUR\")\n",
        "   ```\n",
        "\n",
        "2. **AIMessage**: LLM response (can include tool_calls)\n",
        "   ```python\n",
        "   AIMessage(content=\"Let me convert that for you\", tool_calls=[...])\n",
        "   ```\n",
        "\n",
        "3. **ToolMessage**: Tool execution result\n",
        "   ```python\n",
        "   ToolMessage(content=\"100 USD = 92 EUR\", tool_call_id=\"...\")\n",
        "   ```\n",
        "\n",
        "### How State Updates\n",
        "\n",
        "Each node:\n",
        "1. **Reads** current state (`state[\"messages\"]`)\n",
        "2. **Processes** the data (call LLM, execute tools, etc.)\n",
        "3. **Returns** updates (new messages to append)\n",
        "\n",
        "LangGraph **automatically merges** the updates into state before passing to the next node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(currency_converter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(emi_calculator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the LLM with tool binding\n",
        "print(\"Initializing Vertex AI LLM...\")\n",
        "\n",
        "# Create the base LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    temperature=0.3,  # Lower temperature for more consistent, factual responses\n",
        "    max_tokens=1024,\n",
        "    project=os.getenv(\"GOOGLE_PROJECT_ID\"),\n",
        "    location=os.getenv(\"GOOGLE_REGION\")\n",
        ")\n",
        "\n",
        "# Define the tools list\n",
        "tools = [currency_converter, emi_calculator]\n",
        "\n",
        "# Bind tools to the LLM\n",
        "# This tells the LLM: \"You have access to these tools, and here are their schemas\"\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(\"âœ… LLM initialized with tools:\")\n",
        "for tool in tools:\n",
        "    print(f\"   â€¢ {tool.name}: {tool.description[:60]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the agent node that calls the LLM\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Agent node that invokes the LLM with the current conversation state.\n",
        "    \n",
        "    The LLM will analyze the conversation and decide to either:\n",
        "    1. Call one or more tools (returns AIMessage with tool_calls)\n",
        "    2. Provide a final response (returns AIMessage with content only)\n",
        "    \n",
        "    Args:\n",
        "        state: Current graph state containing message history\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with \"messages\" key containing the LLM response\n",
        "    \"\"\"\n",
        "    # Invoke the LLM with the full conversation history\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    \n",
        "    # Return the response wrapped in the expected format\n",
        "    # LangGraph will automatically append this to state[\"messages\"]\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"âœ… Agent node (call_llm) defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the conditional edge logic\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
        "    \"\"\"\n",
        "    Router that determines the next node based on LLM's decision.\n",
        "    \n",
        "    Checks the last message in the conversation:\n",
        "    - If it contains tool_calls â†’ route to \"tools\" node\n",
        "    - Otherwise â†’ route to END (finish execution)\n",
        "    \n",
        "    Args:\n",
        "        state: Current graph state\n",
        "        \n",
        "    Returns:\n",
        "        Either \"tools\" or END constant\n",
        "    \"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    \n",
        "    # If the LLM made tool calls, execute them next\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    \n",
        "    # Otherwise, we're done - return final response\n",
        "    return END\n",
        "\n",
        "print(\"âœ… Router (should_continue) defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the graph\n",
        "print(\"\\nBuilding the StateGraph...\")\n",
        "\n",
        "# Initialize the graph with MessagesState\n",
        "workflow = StateGraph(MessagesState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"agent\", call_llm)  # The LLM agent\n",
        "workflow.add_node(\"tools\", ToolNode(tools))  # Tool execution node\n",
        "\n",
        "# Add edges\n",
        "workflow.add_edge(START, \"agent\")  # Always start with the agent\n",
        "\n",
        "# Add conditional edge from agent\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",  # Use this function to decide\n",
        "    should_continue,  # Use this function to decide\n",
        "    # Possible destinations:\n",
        "    {\n",
        "        \"tools\": \"tools\",  # If should_continue returns \"tools\", go to tools node\n",
        "        END: END  # If should_continue returns END, finish\n",
        "    }\n",
        ")\n",
        "\n",
        "# After tools execute, always loop back to agent\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# Compile the graph into an executable app\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"âœ… Graph compiled successfully!\")\n",
        "print(\"\\nGraph Structure:\")\n",
        "print(\"  START â†’ agent â†’ [conditional router]\")\n",
        "print(\"            â†“              â†“\")\n",
        "print(\"          tools â†â”€â”€â”€â”€â”€â”€â”€â”€ END\")\n",
        "print(\"            â†“\")\n",
        "print(\"          agent (loop back)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mermaid_diagram = app.get_graph().draw_mermaid()\n",
        "render_mermaid(mermaid_diagram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Graph Flow\n",
        "\n",
        "### What Just Happened?\n",
        "\n",
        "We built a graph with:\n",
        "\n",
        "1. **2 Nodes:**\n",
        "   - `agent`: Calls the LLM to decide what to do\n",
        "   - `tools`: Executes the tools the LLM requested\n",
        "\n",
        "2. **3 Edge Types:**\n",
        "   - **Static edge** (START â†’ agent): Always go here first\n",
        "   - **Conditional edge** (agent â†’ tools/END): Router decides based on LLM response\n",
        "   - **Static edge** (tools â†’ agent): Always loop back after tool execution\n",
        "\n",
        "3. **The Cycle:**\n",
        "   ```\n",
        "   agent â†’ tools â†’ agent â†’ tools â†’ agent â†’ END\n",
        "   ```\n",
        "   This allows multi-step reasoning:\n",
        "   - LLM calls tool\n",
        "   - Tool returns result\n",
        "   - LLM sees result, decides if it needs more tools\n",
        "   - Repeats until LLM has enough info to respond"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why This Works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''sequenceDiagram\n",
        "    participant U as User\n",
        "    participant A as Agent (LLM)\n",
        "    participant T as Tools\n",
        "    \n",
        "    U->>A: Convert 100 USD to EUR\n",
        "    A->>A: Analyze query\n",
        "    A->>T: Call currency_converter\n",
        "    T->>T: Execute conversion\n",
        "    T->>A: Return 100 USD = 92 EUR\n",
        "    A->>A: Synthesize response\n",
        "    A->>U: 100 USD equals 92 EUR''', 900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The LLM acts as the **orchestrator**:\n",
        "- It sees the full conversation (including tool results)\n",
        "- It autonomously decides when to use tools\n",
        "- It determines when it has enough information\n",
        "- It controls the execution flow through its responses\n",
        "\n",
        "**You** define the tools and graph structure.  \n",
        "**The LLM** decides the execution path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 5: Execution Examples\n",
        "\n",
        "## Testing the Agentic Graph\n",
        "\n",
        "We'll test 5 different execution patterns:\n",
        "\n",
        "1. **Single Tool Call**: Simple, one-step task\n",
        "2. **Multiple Sequential Calls**: Agent loops to gather more info\n",
        "3. **Dependent Sequential Tasks**: Second task needs first result\n",
        "4. **Conversational Context**: Multi-turn conversation with state\n",
        "5. **Parallel Tool Execution**: Independent tasks run simultaneously\n",
        "\n",
        "Each example demonstrates different aspects of the agent's decision-making."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXAMPLE 1: Single Tool Call\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nQuery: 'What is 1000 USD in EUR?'\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial state with user message\n",
        "state = {\"messages\": [HumanMessage(content=\"What is 1000 USD in EUR?\")]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the graph\n",
        "result = app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the conversation flow\n",
        "print(\"CONVERSATION FLOW:\")\n",
        "print(\"-\" * 70)\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"\\n[{i}] ðŸ‘¤ USER:\")\n",
        "        print(f\"    {msg.content}\")\n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT (calling tools):\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"    â†’ Tool: {tc['name']}\")\n",
        "                print(f\"      Args: {tc['args']}\")\n",
        "        else:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT (final response):\")\n",
        "            print(f\"    {msg.content}\")\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"\\n[{i}] ðŸ”§ TOOL RESULT:\")\n",
        "        print(f\"    {msg.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYSIS:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"âœ… Single tool call pattern\")\n",
        "print(\"âœ… Agent identified need for currency_converter\")\n",
        "print(\"âœ… Tool executed and returned result\")\n",
        "print(\"âœ… Agent formulated natural language response\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXAMPLE 2: Multiple Sequential Tool Calls (Information Gathering)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nQuery: 'Convert 1000 USD to EUR and also calculate EMI for USD 500000 at 8.5% for 5 years'\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial state\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 1000 USD to EUR and also calculate EMI for USD 500000 at 8.5% for 5 years\")\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.stream(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Execute with streaming to see each step\n",
        "print(\"EXECUTION STEPS:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "step_count = 0\n",
        "for event in app.stream(state):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: {node_name}\")\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            last_msg = data[\"messages\"][-1]\n",
        "            \n",
        "            if isinstance(last_msg, AIMessage) and hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "                print(f\"  ðŸ¤– Agent Decision: Call {len(last_msg.tool_calls)} tool(s)\")\n",
        "                for tc in last_msg.tool_calls:\n",
        "                    print(f\"     â€¢ {tc['name']}({tc['args']})\")\n",
        "                    \n",
        "            elif isinstance(last_msg, ToolMessage):\n",
        "                print(f\"  ðŸ”§ Tool Execution Complete\")\n",
        "                print(f\"     Result preview: {last_msg.content}...\")\n",
        "                \n",
        "            elif isinstance(last_msg, AIMessage):\n",
        "                print(f\"  ðŸ’¬ Final Response Generated\")\n",
        "\n",
        "# Get final result\n",
        "result = app.invoke(state)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL RESPONSE:\")\n",
        "print(\"=\" * 70)\n",
        "content = result[\"messages\"][-1].content\n",
        "if type(content) == list:\n",
        "    print(content[0]['text'])\n",
        "else:\n",
        "    print(content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYSIS:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"âœ… Agent handled multi-part query\")\n",
        "print(\"âœ… Both tools called in single decision (potentially parallel)\")\n",
        "print(\"âœ… Results synthesized into coherent response\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXAMPLE 2a: Multiple Sequential Tool Calls (Information Gathering)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nQuery: 'Convert 1000 USD to EUR and also calculate EMI for USD 500000 at 8.5% for 5 years'\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial state\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 1000 USD to EUR \"),\n",
        "        HumanMessage(content=\"Calculate EMI for USD 500000 at 8.5% for 5 years\")\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Execute with streaming to see each step\n",
        "print(\"EXECUTION STEPS:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "step_count = 0\n",
        "for event in app.stream(state):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: {node_name}\")\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            last_msg = data[\"messages\"][-1]\n",
        "            \n",
        "            if isinstance(last_msg, AIMessage) and hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "                print(f\"  ðŸ¤– Agent calling: {last_msg.tool_calls[0]['name']}\")\n",
        "                print(f\"     Args: {last_msg.tool_calls[0]['args']}\")\n",
        "                    \n",
        "            elif isinstance(last_msg, ToolMessage):\n",
        "                print(f\"  ðŸ”§ Tool Execution Complete\")\n",
        "                print(f\"     Result preview: {last_msg.content}...\")\n",
        "                \n",
        "            elif isinstance(last_msg, AIMessage):\n",
        "                print(f\"  ðŸ’¬ Final Response Generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get final result\n",
        "result = app.invoke(state)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL RESPONSE:\")\n",
        "print(\"=\" * 70)\n",
        "content = result[\"messages\"][-1].content\n",
        "if type(content) == list:\n",
        "    print(content[0]['text'])\n",
        "else:\n",
        "    print(content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYSIS:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"âœ… Agent handled multi-part query\")\n",
        "print(\"âœ… Both tools called in single decision (potentially parallel)\")\n",
        "print(\"âœ… Results synthesized into coherent response\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXAMPLE 3: Dependent Sequential Execution\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nQuery: 'Convert 100000 INR to USD, then calculate EMI for THAT amount at 7% for 24 months'\\n\")\n",
        "print(\"NOTE: The second task DEPENDS on the first result - must execute sequentially!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create initial state\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(\n",
        "            content=\"Convert 100000 INR to USD, then calculate EMI for that USD amount at 7% interest for 24 months\"\n",
        "        )\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Execute with streaming\n",
        "print(\"EXECUTION TRACE:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "step_count = 0\n",
        "for event in app.stream(state):\n",
        "    print(event.items())\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: {node_name}\")\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            last_msg = data[\"messages\"][-1]\n",
        "            \n",
        "            if isinstance(last_msg, AIMessage) and hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "                print(f\"  ðŸ¤– Agent calling: {last_msg.tool_calls[0]['name']}\")\n",
        "                print(f\"     Args: {last_msg.tool_calls[0]['args']}\")\n",
        "                \n",
        "            elif isinstance(last_msg, ToolMessage):\n",
        "                print(f\"  âœ… Tool completed\")\n",
        "                print(f\"     Output: {last_msg.content[:150]}...\")\n",
        "                \n",
        "            elif isinstance(last_msg, AIMessage):\n",
        "                print(f\"  ðŸ’¬ Agent: Task complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get final result\n",
        "result = app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL RESPONSE:\")\n",
        "print(\"=\" * 70)\n",
        "final_message = result[\"messages\"][-1]\n",
        "print(final_message.content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYSIS:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"âœ… Agent recognized task dependency\")\n",
        "print(\"âœ… First: Convert INR â†’ USD\")\n",
        "print(\"âœ… Then: Use converted amount in EMI calculation\")\n",
        "print(\"âœ… Sequential execution required (not parallel)\")\n",
        "print(\"\\nðŸ’¡ Key Insight: The agent automatically detected that the second\")\n",
        "print(\"   task depends on the first result and executed them in sequence!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXAMPLE 4: Conversational Context (Multi-Turn)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nThis demonstrates how state persists across multiple interactions.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Turn 1: Initial query\n",
        "print(\"[TURN 1]\")\n",
        "print(\"-\" * 70)\n",
        "state = {\"messages\": [HumanMessage(content=\"Convert 5000 GBP to INR\")]}\n",
        "result = app.invoke(state)\n",
        "print(f\"ðŸ‘¤ User: {state['messages'][0].content}\")\n",
        "print(f\"ðŸ¤– Assistant: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Turn 2: Follow-up query that references previous result\n",
        "print(\"\\n[TURN 2]\")\n",
        "print(\"-\" * 70)\n",
        "print(\"ðŸ‘¤ User: Now calculate EMI for that INR amount at 9% for 2 years\")\n",
        "result[\"messages\"].append(\n",
        "    HumanMessage(content=\"Now calculate EMI for that INR amount at 9% for 2 years\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = app.invoke(result)\n",
        "print(f\"ðŸ¤– Assistant: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYSIS:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"âœ… Agent maintained context from Turn 1\")\n",
        "print(\"âœ… Understood 'that INR amount' referred to previous conversion result\")\n",
        "print(\"âœ… State contains full conversation history\")\n",
        "print(\"\\nðŸ’¡ Key Insight: MessagesState automatically preserves all messages,\")\n",
        "print(\"   enabling natural conversational flow with context awareness!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXAMPLE 5: Parallel Tool Execution\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nQuery: 'Convert 500000 INR to USD AND ALSO compute EMI for 500000 at 8.5% for 24 months'\\n\")\n",
        "print(\"NOTE: Both tasks are INDEPENDENT - can execute in parallel!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial state\n",
        "input_message = HumanMessage(\n",
        "    content=\"Convert INR 500,000 to USD and also compute EMI at 8.5% for a 24 month loan of INR 200,000\"\n",
        ")\n",
        "initial_state = {\"messages\": [input_message]}\n",
        "\n",
        "print(f\"User Query: {input_message.content}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.invoke(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Execute with streaming to observe parallel execution\n",
        "print(\"PROCESSING STEPS:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "step_count = 0\n",
        "for event in app.stream(initial_state):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: {node_name}\")\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            last_msg = data[\"messages\"][-1]\n",
        "            \n",
        "            if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "                # Check if multiple tools are called at once\n",
        "                if len(last_msg.tool_calls) > 1:\n",
        "                    print(f\"  ðŸš€ PARALLEL Execution: {len(last_msg.tool_calls)} tools called simultaneously!\")\n",
        "                    for tc in last_msg.tool_calls:\n",
        "                        print(f\"     â€¢ {tc['name']}\")\n",
        "                        print(f\"       Args: {tc['args']}\")\n",
        "                else:\n",
        "                    for tc in last_msg.tool_calls:\n",
        "                        print(f\"  ðŸ”§ Tool Call: {tc['name']}\")\n",
        "                        print(f\"     Args: {tc['args']}\")\n",
        "                        \n",
        "            elif hasattr(last_msg, \"content\") and last_msg.content:\n",
        "                print(f\"  ðŸ’¬ Response: {last_msg.content}\")\n",
        "\n",
        "# Get final result\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL RESPONSE:\")\n",
        "print(\"=\" * 70)\n",
        "final_message = result[\"messages\"][-1]\n",
        "print(final_message.content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"KEY INSIGHT: Parallel vs Sequential Execution\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nðŸ“Š COMPARISON:\\n\")\n",
        "print(\"Example 3 (Sequential):\")\n",
        "print(\"  Query: 'Convert INR to USD THEN calculate EMI for THAT amount'\")\n",
        "print(\"  â†’ Second task depends on first result\")\n",
        "print(\"  â†’ MUST run sequentially\")\n",
        "print(\"  â†’ Execution: Tool1 â†’ Agent â†’ Tool2 â†’ Agent â†’ Response\")\n",
        "print(\"\\nExample 5 (Parallel):\")\n",
        "print(\"  Query: 'Convert INR to USD AND ALSO compute EMI for 500k'\")\n",
        "print(\"  â†’ Both tasks are independent\")\n",
        "print(\"  â†’ CAN run in parallel\")\n",
        "print(\"  â†’ Execution: Tool1 + Tool2 (simultaneous) â†’ Agent â†’ Response\")\n",
        "print(\"\\nðŸ’¡ The agent intelligently analyzes task dependencies and\")\n",
        "print(\"   automatically chooses sequential or parallel execution!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 6: Understanding Graph Execution\n",
        "\n",
        "## How the Graph Executes: Deep Dive\n",
        "\n",
        "### Execution Lifecycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''sequenceDiagram\n",
        "    participant User\n",
        "    participant Graph\n",
        "    participant Agent\n",
        "    participant Router\n",
        "    participant Tools\n",
        "    \n",
        "    User->>Graph: invoke(state)\n",
        "    Graph->>Agent: state with user message\n",
        "    Agent->>Agent: LLM analyzes query\n",
        "    Agent->>Graph: AIMessage (with/without tool_calls)\n",
        "    Graph->>Router: Check last message\n",
        "    \n",
        "    alt Has tool_calls\n",
        "        Router->>Tools: Execute tools\n",
        "        Tools->>Tools: Run Python functions\n",
        "        Tools->>Graph: ToolMessage(s) with results\n",
        "        Graph->>Agent: Updated state (loop back)\n",
        "        Agent->>Agent: LLM sees tool results\n",
        "        Agent->>Graph: AIMessage (decision)\n",
        "        Graph->>Router: Check again\n",
        "    end\n",
        "    \n",
        "    Router->>Graph: Route to END\n",
        "    Graph->>User: Final state returned''', 900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Observations\n",
        "\n",
        "**State is Immutable Per Node**\n",
        "- Nodes return updates, not modified state\n",
        "- LangGraph merges updates automatically\n",
        "- Previous messages never disappear\n",
        "\n",
        "**Cycles Enable Reasoning**\n",
        "- Tools â†’ Agent loop allows multi-step tasks\n",
        "- Agent can call tools multiple times\n",
        "- Terminates when agent is satisfied\n",
        "\n",
        "**Streaming Shows Real-Time Progress**\n",
        "- `.stream()` yields each node's output\n",
        "- Useful for debugging and UX (loading indicators)\n",
        "- `.invoke()` waits for completion\n",
        "\n",
        "**Parallel Tool Calls**\n",
        "- LLM can include multiple tool_calls in one AIMessage\n",
        "- ToolNode executes them all\n",
        "- Results appended in order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                  LANGGRAPH FEATURES DEMONSTRATED                  â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "âœ… STATE MANAGEMENT\n",
        "   â€¢ MessagesState persists conversation history\n",
        "   â€¢ State flows through nodes automatically\n",
        "   â€¢ Immutable updates merged by framework\n",
        "\n",
        "âœ… NODES (Modular Functions)\n",
        "   â€¢ Agent Node: LLM decision-making\n",
        "   â€¢ Tools Node: Execute Python functions\n",
        "   â€¢ Custom logic encapsulated\n",
        "\n",
        "âœ… EDGES (Flow Control)\n",
        "   â€¢ Static: START â†’ agent, tools â†’ agent\n",
        "   â€¢ Conditional: agent â†’ tools/END based on router\n",
        "\n",
        "âœ… CONDITIONAL ROUTING\n",
        "   â€¢ Router function examines state\n",
        "   â€¢ Dynamic path selection\n",
        "   â€¢ Enables agentic autonomy\n",
        "\n",
        "âœ… TOOL CALLING\n",
        "   â€¢ LLM decides when to use tools\n",
        "   â€¢ Type-safe parameter passing\n",
        "   â€¢ Error handling at tool level\n",
        "\n",
        "âœ… CYCLES (Iterative Reasoning)\n",
        "   â€¢ tools â†’ agent â†’ tools loop\n",
        "   â€¢ Multi-step problem solving\n",
        "   â€¢ Terminates when agent decides\n",
        "\n",
        "âœ… STREAMING\n",
        "   â€¢ Real-time execution visibility\n",
        "   â€¢ Observe agent's decision process\n",
        "   â€¢ Useful for debugging and UX\n",
        "\n",
        "âœ… PARALLEL EXECUTION\n",
        "   â€¢ LLM calls multiple tools simultaneously\n",
        "   â€¢ When tasks are independent\n",
        "   â€¢ Automatic orchestration\n",
        "\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘            WHAT MAKES THIS \"AGENTIC\"?                             â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "The LLM AUTONOMOUSLY decides:\n",
        "  â†’ Which tools to call (if any)\n",
        "  â†’ When to call them (sequential vs parallel)\n",
        "  â†’ How many reasoning loops it needs\n",
        "  â†’ When it has enough information to respond\n",
        "\n",
        "YOU define:\n",
        "  â†’ Available tools (capabilities)\n",
        "  â†’ Graph structure (possible paths)\n",
        "  â†’ Routing logic (decision points)\n",
        "\n",
        "The agent operates within these constraints but controls execution flow.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 7: Hands-On Exercise\n",
        "\n",
        "## ðŸŽ¯ Hands-On Exercise: Compound Interest Calculator\n",
        "\n",
        "### Objective\n",
        "Extend the financial assistant by adding a compound interest calculator tool.\n",
        "\n",
        "### Learning Goals\n",
        "1. Create a custom tool from scratch\n",
        "2. Implement financial formula correctly\n",
        "3. Integrate new tool into existing graph\n",
        "4. Test with complex queries\n",
        "\n",
        "### Part 1: Implement the Tool\n",
        "\n",
        "Complete the function below using the compound interest formula:\n",
        "\n",
        "```\n",
        "A = P(1 + r/n)^(nt)\n",
        "```\n",
        "\n",
        "Where:\n",
        "- **A** = Final amount\n",
        "- **P** = Principal (initial investment)\n",
        "- **r** = Annual interest rate (as decimal, e.g., 0.06 for 6%)\n",
        "- **n** = Compounding frequency per year (e.g., 12 for monthly)\n",
        "- **t** = Time in years\n",
        "\n",
        "### Expected Output Format\n",
        "\n",
        "```\n",
        "Compound Interest Calculation:\n",
        "  Initial Principal: â‚¹10,000.00\n",
        "  Annual Interest Rate: 6%\n",
        "  Investment Period: 5 years\n",
        "  Compounding: 12 times/year (Monthly)\n",
        "  ---\n",
        "  Final Amount: â‚¹13,488.50\n",
        "  Interest Earned: â‚¹3,488.50\n",
        "  Effective Annual Rate: 6.17%\n",
        "```\n",
        "\n",
        "### Test Cases\n",
        "\n",
        "**Test 1:** Principal=10000, Rate=6%, Years=5, Compounds=12\n",
        "- Expected Final: â‚¹13,488.50\n",
        "\n",
        "**Test 2:** Principal=50000, Rate=8%, Years=10, Compounds=4\n",
        "- Expected Final: â‚¹110,278.85\n",
        "\n",
        "**Test 3:** Principal=100000, Rate=0%, Years=5, Compounds=12\n",
        "- Expected Final: â‚¹100,000.00 (edge case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def compound_interest_calculator(\n",
        "    principal: float, \n",
        "    annual_rate: float, \n",
        "    years: int, \n",
        "    compounds_per_year: int = 12\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Calculate compound interest on an investment.\n",
        "    \n",
        "    Formula: A = P(1 + r/n)^(nt)\n",
        "    \n",
        "    Args:\n",
        "        principal: Initial investment amount\n",
        "        annual_rate: Annual interest rate as percentage (e.g., 6 for 6%)\n",
        "        years: Investment period in years\n",
        "        compounds_per_year: How often interest compounds per year (default: 12 for monthly)\n",
        "    \n",
        "    Returns:\n",
        "        A string with detailed calculation results\n",
        "    \"\"\"\n",
        "    # TODO: Implement input validation\n",
        "    # Hint: Check that principal > 0, annual_rate >= 0, years > 0, compounds_per_year > 0\n",
        "    \n",
        "    # TODO: Convert annual_rate from percentage to decimal\n",
        "    # Hint: r = annual_rate / 100\n",
        "    \n",
        "    # TODO: Calculate final amount using the formula\n",
        "    # Hint: A = principal * (1 + r/compounds_per_year) ** (compounds_per_year * years)\n",
        "    \n",
        "    # TODO: Calculate interest earned\n",
        "    # Hint: interest = final_amount - principal\n",
        "    \n",
        "    # TODO: Calculate effective annual rate\n",
        "    # Hint: effective_rate = ((1 + r/compounds_per_year) ** compounds_per_year - 1) * 100\n",
        "    \n",
        "    # TODO: Format and return the result string\n",
        "    # Use the expected output format shown above\n",
        "    \n",
        "    pass\n",
        "\n",
        "# ============================================================================\n",
        "# YOUR CODE BELOW: Uncomment and complete the implementation\n",
        "# ============================================================================\n",
        "\n",
        "# # Validation\n",
        "# if principal <= 0:\n",
        "#     return \"Error: Principal must be greater than 0\"\n",
        "# # ... add more validations\n",
        "#\n",
        "# # Convert rate\n",
        "# r = # YOUR CODE HERE\n",
        "#\n",
        "# # Calculate final amount\n",
        "# final_amount = # YOUR CODE HERE\n",
        "#\n",
        "# # Calculate interest earned\n",
        "# interest_earned = # YOUR CODE HERE\n",
        "#\n",
        "# # Calculate effective annual rate\n",
        "# effective_rate = # YOUR CODE HERE\n",
        "#\n",
        "# # Format result\n",
        "# result = (\n",
        "#     f\"Compound Interest Calculation:\\n\"\n",
        "#     # ... complete the formatting\n",
        "# )\n",
        "#\n",
        "# return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test your compound interest calculator before integrating with graph\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TESTING: Compound Interest Calculator\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test Case 1: Standard case\n",
        "print(\"\\n[Test 1] â‚¹10,000 at 6% for 5 years (monthly compounding)\")\n",
        "try:\n",
        "    result = compound_interest_calculator.invoke({\n",
        "        \"principal\": 10000,\n",
        "        \"annual_rate\": 6,\n",
        "        \"years\": 5,\n",
        "        \"compounds_per_year\": 12\n",
        "    })\n",
        "    print(result)\n",
        "    print(\"âœ… Expected final amount: ~â‚¹13,488.50\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")\n",
        "\n",
        "# Test Case 2: Quarterly compounding\n",
        "print(\"\\n[Test 2] â‚¹50,000 at 8% for 10 years (quarterly compounding)\")\n",
        "try:\n",
        "    result = compound_interest_calculator.invoke({\n",
        "        \"principal\": 50000,\n",
        "        \"annual_rate\": 8,\n",
        "        \"years\": 10,\n",
        "        \"compounds_per_year\": 4\n",
        "    })\n",
        "    print(result)\n",
        "    print(\"âœ… Expected final amount: ~â‚¹110,278.85\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")\n",
        "\n",
        "# Test Case 3: Zero interest (edge case)\n",
        "print(\"\\n[Test 3] â‚¹100,000 at 0% for 5 years\")\n",
        "try:\n",
        "    result = compound_interest_calculator.invoke({\n",
        "        \"principal\": 100000,\n",
        "        \"annual_rate\": 0,\n",
        "        \"years\": 5,\n",
        "        \"compounds_per_year\": 12\n",
        "    })\n",
        "    print(result)\n",
        "    print(\"âœ… Expected final amount: â‚¹100,000.00 (no growth)\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Integrate Tool into Graph\n",
        "\n",
        "Once your tool works correctly, integrate it into the agentic graph.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. **Add to Tools List**\n",
        "   ```python\n",
        "   tools = [currency_converter, emi_calculator, compound_interest_calculator]\n",
        "   ```\n",
        "\n",
        "2. **Rebind LLM**\n",
        "   ```python\n",
        "   llm_with_tools = llm.bind_tools(tools)\n",
        "   ```\n",
        "\n",
        "3. **Rebuild Graph**\n",
        "   ```python\n",
        "   # Recreate workflow with updated tools\n",
        "   workflow = StateGraph(MessagesState)\n",
        "   workflow.add_node(\"agent\", call_llm)\n",
        "   workflow.add_node(\"tools\", ToolNode(tools))  # Now includes compound_interest_calculator\n",
        "   \n",
        "   workflow.add_edge(START, \"agent\")\n",
        "   workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "   workflow.add_edge(\"tools\", \"agent\")\n",
        "   \n",
        "   app = workflow.compile()\n",
        "   ```\n",
        "\n",
        "4. **Test with Natural Language**\n",
        "   ```python\n",
        "   state = {\"messages\": [HumanMessage(content=\"Calculate compound interest on â‚¹10,000 at 6% for 5 years\")]}\n",
        "   result = app.invoke(state)\n",
        "   print(result[\"messages\"][-1].content)\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Add your compound_interest_calculator to the tools list\n",
        "# tools = [currency_converter, emi_calculator]  # Add your tool here!\n",
        "\n",
        "# TODO: Rebind the LLM with the updated tools list\n",
        "# llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# TODO: Rebuild the graph (copy the graph building code from earlier)\n",
        "# workflow = StateGraph(MessagesState)\n",
        "# ... add nodes and edges\n",
        "# app = workflow.compile()\n",
        "\n",
        "# TODO: Test with a simple query\n",
        "# state = {\"messages\": [HumanMessage(content=\"Calculate compound interest on â‚¹10,000 at 6% for 5 years\")]}\n",
        "# result = app.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "\n",
        "print(\"âš ï¸  Complete the TODOs above to integrate your tool!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Complex Query Challenge\n",
        "\n",
        "### Challenge Queries\n",
        "\n",
        "Test your integrated system with these complex scenarios:\n",
        "\n",
        "**Challenge 1: Sequential Dependency**\n",
        "```\n",
        "\"If I invest â‚¹50,000 at 7% compound interest for 3 years with quarterly \n",
        "compounding, then take a loan for the final amount at 9% interest for \n",
        "2 years, what would be my monthly EMI?\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''graph LR\n",
        "    A[Query] --> B[Compound Interest]\n",
        "    B --> C[Get Final Amount]\n",
        "    C --> D[EMI Calculator]\n",
        "    D --> E[Final Response]\n",
        "    \n",
        "    style A fill:#87CEEB\n",
        "    style B fill:#FFD700\n",
        "    style C fill:#90EE90\n",
        "    style D fill:#FFD700\n",
        "    style E fill:#FFB6C1''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Flow:**\n",
        "1. Calculate compound interest â†’ Get final amount\n",
        "2. Use that amount as loan principal â†’ Calculate EMI\n",
        "\n",
        "**Challenge 2: Currency + Compound Interest**\n",
        "```\n",
        "\"Convert 10,000 USD to INR, then calculate compound interest on that \n",
        "INR amount at 8% for 5 years with monthly compounding\"\n",
        "```\n",
        "\n",
        "**Challenge 3: Parallel Execution**\n",
        "```\n",
        "\"Calculate compound interest on â‚¹100,000 at 6% for 10 years AND ALSO \n",
        "compute EMI for â‚¹500,000 at 8.5% for 5 years\"\n",
        "```\n",
        "\n",
        "**Question:** Will this execute sequentially or in parallel? Why?\n",
        "\n",
        "### Success Criteria\n",
        "\n",
        "âœ… Agent correctly identifies task dependencies  \n",
        "âœ… Sequential tasks execute in proper order  \n",
        "âœ… Parallel tasks execute simultaneously when independent  \n",
        "âœ… Final response synthesizes all results coherently  \n",
        "âœ… No hallucinations - all numbers come from tool results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test your integrated system with the challenges\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CHALLENGE 1: Sequential Dependency\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TODO: Uncomment and run after completing Part 2\n",
        "# state = {\"messages\": [HumanMessage(content=\"\"\"\n",
        "# If I invest â‚¹50,000 at 7% compound interest for 3 years with quarterly \n",
        "# compounding, then take a loan for the final amount at 9% interest for \n",
        "# 2 years, what would be my monthly EMI?\n",
        "# \"\"\")]}\n",
        "# \n",
        "# for event in app.stream(state):\n",
        "#     for node_name, data in event.items():\n",
        "#         print(f\"\\n[Node: {node_name}]\")\n",
        "#         if \"messages\" in data:\n",
        "#             last_msg = data[\"messages\"][-1]\n",
        "#             if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "#                 for tc in last_msg.tool_calls:\n",
        "#                     print(f\"  ðŸ”§ Calling: {tc['name']}\")\n",
        "# \n",
        "# result = app.invoke(state)\n",
        "# print(\"\\nFINAL ANSWER:\")\n",
        "# print(result[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nðŸ’¡ Analyze the execution trace:\")\n",
        "print(\"   â€¢ Did compound_interest_calculator run first?\")\n",
        "print(\"   â€¢ Did emi_calculator use the compound interest result?\")\n",
        "print(\"   â€¢ How many agent â†’ tools cycles occurred?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# SECTION 8: Conclusion & Next Steps\n",
        "\n",
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You've successfully built an agentic financial assistant using LangGraph!\n",
        "\n",
        "### What You Accomplished\n",
        "\n",
        "âœ… **Created Custom Tools**\n",
        "   - Currency converter with multi-currency support\n",
        "   - EMI calculator with proper financial formula\n",
        "   - Compound interest calculator (in exercise)\n",
        "\n",
        "âœ… **Built LangGraph Workflow**\n",
        "   - Defined StateGraph with MessagesState\n",
        "   - Implemented agent node (LLM decision-maker)\n",
        "   - Created tool execution node\n",
        "   - Configured conditional routing\n",
        "\n",
        "âœ… **Mastered Execution Patterns**\n",
        "   - Single tool calls\n",
        "   - Sequential multi-step reasoning\n",
        "   - Dependent task chaining\n",
        "   - Conversational context maintenance\n",
        "   - Parallel tool execution\n",
        "\n",
        "âœ… **Understood Agentic Behavior**\n",
        "   - LLM autonomously decides tool usage\n",
        "   - Automatic sequential vs parallel detection\n",
        "   - State-driven conversational flow\n",
        "   - Cyclic execution for complex tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Concepts Learned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render Mermaid diagram\n",
        "render_mermaid('''mindmap\n",
        "  root((LangGraph))\n",
        "    State Management\n",
        "      MessagesState\n",
        "      Message Types\n",
        "      Immutable Updates\n",
        "    Nodes\n",
        "      Agent Node\n",
        "      Tools Node\n",
        "      Custom Functions\n",
        "    Edges\n",
        "      Static Edges\n",
        "      Conditional Edges\n",
        "      Routing Logic\n",
        "    Execution\n",
        "      Cycles\n",
        "      Streaming\n",
        "      Parallel Tools''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture Pattern\n",
        "\n",
        "```\n",
        "User Query â†’ State â†’ Agent (LLM) â†’ [Tools?] â†’ Response\n",
        "                         â†‘              â†“\n",
        "                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                         (Loop until satisfied)\n",
        "```\n",
        "\n",
        "This pattern applies to:\n",
        "- Research agents (search â†’ analyze â†’ summarize)\n",
        "- Customer support bots (lookup â†’ execute â†’ respond)\n",
        "- Data analysis assistants (query â†’ compute â†’ visualize)\n",
        "- Code assistants (analyze â†’ execute â†’ debug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps: Advancing Your LangGraph Skills\n",
        "\n",
        "### 1. Observability with LangSmith\n",
        "\n",
        "Access your execution traces:\n",
        "- Visit LangSmith Dashboard\n",
        "- View detailed token usage, latency, costs\n",
        "- Debug complex execution flows\n",
        "- Optimize performance bottlenecks\n",
        "\n",
        "### 2. Advanced LangGraph Patterns\n",
        "\n",
        "**Human-in-the-Loop**\n",
        "- Pause execution for approval\n",
        "- Allow manual tool selection\n",
        "- Implement safety checks\n",
        "\n",
        "**Sub-Graphs**\n",
        "- Compose smaller graphs into larger workflows\n",
        "- Modular architecture for complex systems\n",
        "\n",
        "**Persistence**\n",
        "- Checkpoint state to resume later\n",
        "- Long-running workflows across sessions\n",
        "\n",
        "**Error Handling**\n",
        "- Retry logic for failed tools\n",
        "- Fallback paths for degraded service\n",
        "- Graceful error recovery\n",
        "\n",
        "### 3. Extend This Application\n",
        "\n",
        "**Additional Tools:**\n",
        "- Stock price fetcher (real-time API)\n",
        "- Tax calculator (based on income brackets)\n",
        "- Investment portfolio analyzer\n",
        "- Loan comparison tool\n",
        "\n",
        "**Enhanced Agent:**\n",
        "- Add memory beyond current session\n",
        "- Implement user preferences\n",
        "- Multi-turn planning for complex financial scenarios\n",
        "\n",
        "**Production Readiness:**\n",
        "- Input sanitization and validation\n",
        "- Rate limiting for tool calls\n",
        "- Caching for repeated queries\n",
        "- Authentication and authorization\n",
        "\n",
        "### 4. Real-World Project Ideas\n",
        "\n",
        "1. **Research Assistant**\n",
        "   - Web search â†’ Summarization â†’ Citation management\n",
        "   \n",
        "2. **Code Review Bot**\n",
        "   - Static analysis â†’ Test execution â†’ Report generation\n",
        "\n",
        "3. **Travel Planner**\n",
        "   - Flight search â†’ Hotel booking â†’ Itinerary optimization\n",
        "\n",
        "4. **Customer Support Agent**\n",
        "   - Ticket lookup â†’ Knowledge base search â†’ Response generation\n",
        "\n",
        "### 5. Learn More\n",
        "\n",
        "**Documentation:**\n",
        "- LangGraph Docs: https://langchain-ai.github.io/langgraph/\n",
        "- LangChain Docs: https://python.langchain.com/\n",
        "\n",
        "**Community:**\n",
        "- LangChain Discord\n",
        "- GitHub Discussions\n",
        "- Stack Overflow `langgraph` tag\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ You're Ready to Build Agentic Applications!\n",
        "\n",
        "The patterns you learned here apply to virtually any LLM-powered workflow. Start small, iterate, and gradually build complexity.\n",
        "\n",
        "**Remember:**\n",
        "- Tools extend LLM capabilities\n",
        "- State enables conversational context\n",
        "- Routing creates dynamic behavior\n",
        "- Cycles allow iterative reasoning\n",
        "\n",
        "Now go build something amazing! ðŸŽ¯"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Issues & Solutions\n",
        "\n",
        "### Issue 1: Tool Not Being Called\n",
        "\n",
        "**Symptom:** Agent responds without using tools, even when needed\n",
        "\n",
        "**Causes:**\n",
        "- Tool docstring unclear or missing\n",
        "- LLM doesn't understand when to use tool\n",
        "- Tool parameters don't match query\n",
        "\n",
        "**Solutions:**\n",
        "1. Improve docstring with examples\n",
        "2. Explicitly mention tool capabilities in system prompt\n",
        "3. Use more descriptive parameter names\n",
        "4. Test tool schema: `print(tool.args_schema.schema())`\n",
        "\n",
        "---\n",
        "\n",
        "### Issue 2: Graph Loops Infinitely\n",
        "\n",
        "**Symptom:** Execution never reaches END, keeps cycling\n",
        "\n",
        "**Causes:**\n",
        "- Router always returns \"tools\"\n",
        "- LLM never satisfied with results\n",
        "- Conditional logic incorrect\n",
        "\n",
        "**Solutions:**\n",
        "1. Add cycle limit: `app = workflow.compile(recursion_limit=10)`\n",
        "2. Check router logic in `should_continue`\n",
        "3. Verify LLM receives tool results\n",
        "4. Lower temperature for more consistent behavior\n",
        "\n",
        "---\n",
        "\n",
        "### Issue 3: Tool Execution Errors\n",
        "\n",
        "**Symptom:** ToolMessage contains error text\n",
        "\n",
        "**Causes:**\n",
        "- Invalid parameters from LLM\n",
        "- Missing input validation\n",
        "- Type mismatch\n",
        "\n",
        "**Solutions:**\n",
        "1. Add robust error handling in tools\n",
        "2. Validate inputs at tool entry\n",
        "3. Return descriptive error messages\n",
        "4. Check tool binding: `llm_with_tools.bind_tools(tools)`\n",
        "\n",
        "---\n",
        "\n",
        "### Debugging Tips\n",
        "\n",
        "**1. Enable Verbose Mode**\n",
        "```python\n",
        "llm = ChatVertexAI(..., verbose=True)\n",
        "```\n",
        "\n",
        "**2. Print State at Each Step**\n",
        "```python\n",
        "for event in app.stream(state):\n",
        "    print(f\"State: {event}\")\n",
        "```\n",
        "\n",
        "**3. Inspect Tool Calls**\n",
        "```python\n",
        "ai_message = result[\"messages\"][-2]  # Second-to-last message\n",
        "if hasattr(ai_message, \"tool_calls\"):\n",
        "    print(ai_message.tool_calls)\n",
        "```\n",
        "\n",
        "**4. Check Message Types**\n",
        "```python\n",
        "for msg in result[\"messages\"]:\n",
        "    print(f\"{type(msg).__name__}: {msg.content[:50]}\")\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
