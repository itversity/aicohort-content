{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal, List\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"‚úÖ Environment loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "print(\"‚úÖ LLM initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ChromaDB and Embeddings setup\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from google.genai import types\n",
        "\n",
        "# Configuration\n",
        "PERSIST_DIR = \"../../chroma_db\"\n",
        "COLLECTION_NAME = \"toyota_specs\"\n",
        "EMBED_MODEL_ID = \"gemini-embedding-001\"\n",
        "\n",
        "# Initialize embeddings (uses GOOGLE_API_KEY from environment)\n",
        "embeddings_model = GoogleGenerativeAIEmbeddings(\n",
        "    model=EMBED_MODEL_ID,\n",
        "    output_dimensionality=768\n",
        ")\n",
        "\n",
        "# Connect to vectorstore\n",
        "vectorstore = Chroma(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    embedding_function=embeddings_model,\n",
        "    persist_directory=PERSIST_DIR\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Connected to vectorstore: {COLLECTION_NAME}\")\n",
        "print(f\"‚úÖ Using embedding model: {EMBED_MODEL_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorstore.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector similarity search helper\n",
        "def vector_similarity_search(\n",
        "    query: str, \n",
        "    vectorstore, \n",
        "    k: int = 5\n",
        ") -> List[str]:\n",
        "    \"\"\"Perform vector similarity search.\"\"\"\n",
        "    docs = vectorstore.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = vector_similarity_search(\n",
        "    \"What is the base price of the Toyota Camry?\", \n",
        "    vectorstore, \n",
        "    k=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool 1: Vehicle Search\n",
        "@tool\n",
        "def search_vehicles(query: str, max_results: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    Search Toyota vehicle database using semantic similarity.\n",
        "    \n",
        "    Use this tool when users need information about Toyota vehicles,\n",
        "    including specifications, pricing, fuel efficiency, or comparisons.\n",
        "    \n",
        "    Args:\n",
        "        query: Natural language search query about Toyota vehicles\n",
        "        max_results: Maximum number of results to return (default: 5)\n",
        "    \n",
        "    Returns:\n",
        "        Formatted string with vehicle information\n",
        "    \"\"\"\n",
        "    docs = vector_similarity_search(query, vectorstore, k=max_results)\n",
        "    \n",
        "    result = \"Vehicle Search Results:\\n\"\n",
        "    result += \"=\" * 60 + \"\\n\"\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        result += f\"\\nResult {i}:\\n{doc}\\n\"\n",
        "    result += \"=\" * 60\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"‚úÖ search_vehicles tool defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search_vehicles.invoke({\n",
        "    \"query\": \"Which Toyota sedan is most fuel-efficient under $30,000?\",\n",
        "    \"max_results\": 3\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build LangGraph workflow\n",
        "tools = [search_vehicles]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"LLM node: Calls LLM with current messages.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router: Check if agent wants to use tools.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# Build graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"llm\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"llm\")\n",
        "workflow.add_conditional_edges(\"llm\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"llm\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"‚úÖ Graph compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test: Simple vehicle search\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Which Toyota sedan is most fuel-efficient under $30,000?\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query: Which Toyota sedan is most fuel-efficient under $30,000?\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = app.invoke(state)\n",
        "\n",
        "print(f\"\\nTotal messages: {len(result['messages'])}\")\n",
        "print(\"\\nFinal Response:\")\n",
        "print(\"=\" * 70)\n",
        "print(result['messages'][-1].content)\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test: Comparison query\n",
        "state2 = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Compare the Camry and Corolla for city driving\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query: Compare the Camry and Corolla for city driving\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result2 = app.invoke(state2)\n",
        "\n",
        "print(f\"\\nTotal messages: {len(result2['messages'])}\")\n",
        "print(\"\\nFinal Response:\")\n",
        "print(\"=\" * 70)\n",
        "print(result2['messages'][-1].content)\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test: Capability query\n",
        "state3 = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Which Toyota can tow over 5,000 lbs?\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query: Which Toyota can tow over 5,000 lbs?\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result3 = app.invoke(state3)\n",
        "\n",
        "print(f\"\\nTotal messages: {len(result3['messages'])}\")\n",
        "print(\"\\nFinal Response:\")\n",
        "print(\"=\" * 70)\n",
        "print(result3['messages'][-1].content)\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test: Direct tool invocation (without LangGraph)\n",
        "print(\"Direct Tool Test\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "direct_result = search_vehicles.invoke({\n",
        "    \"query\": \"electric Toyota with range over 200 miles\",\n",
        "    \"max_results\": 3\n",
        "})\n",
        "\n",
        "print(\"\\nDirect Search Results:\")\n",
        "print(\"=\" * 70)\n",
        "print(direct_result)\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming execution\n",
        "state_stream = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Show me affordable SUVs with good fuel economy\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Streaming Execution\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Query: Show me affordable SUVs with good fuel economy\\n\")\n",
        "\n",
        "step_count = 0\n",
        "\n",
        "for event in app.stream(state_stream):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: '{node_name}'\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            for msg in data[\"messages\"]:\n",
        "                if isinstance(msg, AIMessage):\n",
        "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "                        print(f\"  üîç Calling {msg.tool_calls[0]['name']}\")\n",
        "                        print(f\"     Query: {msg.tool_calls[0]['args'].get('query')}\")\n",
        "                    else:\n",
        "                        print(f\"  üí¨ Final response generated\")\n",
        "                        \n",
        "                elif isinstance(msg, ToolMessage):\n",
        "                    print(f\"  ‚úÖ Tool executed\")\n",
        "                    first_line = msg.content.split('\\n')[0]\n",
        "                    print(f\"     Result: {first_line}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"Total steps: {step_count}\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
