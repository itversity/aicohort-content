{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Single Tool Execution\n",
        "\n",
        "Understanding how a complete tool execution cycle works in LangGraph.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. **Understand the complete message flow** for single tool execution from user query to final response\n",
        "2. **Examine different message types** (HumanMessage, AIMessage with tool_calls, ToolMessage, AIMessage with content)\n",
        "3. **Trace the execution cycle** through the graph nodes (LLM â†’ Tools â†’ LLM â†’ End)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment setup\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"âœ… Environment loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools\n",
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates or to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \"\"\"\n",
        "    if principal <= 0 or annual_interest_rate < 0 or tenure_months <= 0:\n",
        "        return \"Error: Invalid input parameters\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"âœ… Tools defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize LLM with Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM with tools\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "tools = [currency_converter, emi_calculator]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(\"âœ… LLM initialized with tools\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build graph\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"LLM node that invokes the LLM.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router that decides next step based on tool_calls.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"llm\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"llm\")\n",
        "workflow.add_conditional_edges(\"llm\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"llm\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"âœ… Graph compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Case 1: Currency Conversion\n",
        "\n",
        "Execute a simple currency conversion and trace the message flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Case 1: Currency Conversion\n",
        "state = {\n",
        "    \"messages\": [HumanMessage(content=\"What is 1000 USD in EUR?\")]\n",
        "}\n",
        "\n",
        "print(\"Query: What is 1000 USD in EUR?\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = app.invoke(state)\n",
        "print(f\"\\nTotal messages: {len(result['messages'])}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Message Flow Analysis\n",
        "\n",
        "Let's examine each message in the conversation to understand the complete execution cycle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine message flow\n",
        "print(\"MESSAGE FLOW ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    print(f\"\\n{'â”€' * 70}\")\n",
        "    print(f\"MESSAGE {i}: {type(msg).__name__}\")\n",
        "    print(f\"{'â”€' * 70}\")\n",
        "    \n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"  ðŸ‘¤ USER INPUT\")\n",
        "        print(f\"  Content: {msg.content}\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"  ðŸ¤– AGENT DECISION: Call tool(s)\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"    â€¢ Tool: {tc['name']}\")\n",
        "                print(f\"      Args: {tc['args']}\")\n",
        "        else:\n",
        "            print(f\"  ðŸ¤– AGENT RESPONSE: Final answer\")\n",
        "            print(f\"  Content: {msg.content}\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"  ðŸ”§ TOOL RESULT\")\n",
        "        print(f\"  Content:\\n{msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deep Dive: Individual Messages\n",
        "\n",
        "Examine the structure of each message type in detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deep dive into each message\n",
        "print(\"MESSAGE 1: HumanMessage\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Content: {result['messages'][0].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 2: AIMessage with tool_calls\n",
        "print(\"MESSAGE 2: AIMessage (Tool Call Request)\")\n",
        "print(\"=\" * 70)\n",
        "msg2 = result['messages'][1]\n",
        "print(f\"Has tool_calls: {bool(msg2.tool_calls)}\")\n",
        "print(f\"\\nTool Calls Detail:\")\n",
        "print(msg2.tool_calls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 3: ToolMessage\n",
        "print(\"MESSAGE 3: ToolMessage\")\n",
        "print(\"=\" * 70)\n",
        "msg3 = result['messages'][2]\n",
        "print(f\"Tool Call ID: {msg3.tool_call_id}\")\n",
        "print(f\"\\nContent:\")\n",
        "print(msg3.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message 4: Final AIMessage\n",
        "print(\"MESSAGE 4: AIMessage (Final Response)\")\n",
        "print(\"=\" * 70)\n",
        "msg4 = result['messages'][3]\n",
        "print(f\"Has tool_calls: {bool(msg4.tool_calls) if hasattr(msg4, 'tool_calls') else False}\")\n",
        "print(f\"\\nContent:\")\n",
        "print(msg4.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversation Flow Visualization\n",
        "\n",
        "Visual summary of the complete execution cycle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize conversation flow\n",
        "print(\"CONVERSATION FLOW VISUALIZATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"\\n[{i}] ðŸ‘¤ USER:\")\n",
        "        print(f\"    \\\"{msg.content}\\\"\")\n",
        "        \n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT â†’ Calling tool:\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"    Tool: {tc['name']}\")\n",
        "                print(f\"    Args: {tc['args']}\")\n",
        "        else:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT â†’ Final response:\")\n",
        "            print(f\"    \\\"{msg.content}\\\"\")\n",
        "            \n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"\\n[{i}] ðŸ”§ TOOL RESULT:\")\n",
        "        for line in msg.content.split('\\n'):\n",
        "            print(f\"    {line}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Case 2: EMI Calculation\n",
        "\n",
        "Test with a different tool to verify the pattern holds across different tool types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Case 2: EMI Calculator\n",
        "state2 = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Calculate EMI for a 50000 USD loan at 7.5% for 36 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Query: Calculate EMI for a 50000 USD loan at 7.5% for 36 months\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result2 = app.invoke(state2)\n",
        "print(f\"\\nMessage count: {len(result2['messages'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tool Selection Verification\n",
        "\n",
        "Verify that the LLM correctly selected the EMI calculator tool and extracted the appropriate parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify tool selection\n",
        "print(\"Tool Selection Verification:\")\n",
        "print(\"=\" * 70)\n",
        "tool_call_msg = result2['messages'][1]\n",
        "if tool_call_msg.tool_calls:\n",
        "    tc = tool_call_msg.tool_calls[0]\n",
        "    print(f\"âœ… LLM selected: {tc['name']}\")\n",
        "    print(f\"\\nExtracted parameters:\")\n",
        "    for key, value in tc['args'].items():\n",
        "        print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display conversation flow for EMI test\n",
        "print(\"\\nCONVERSATION FLOW:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result2[\"messages\"], 1):\n",
        "    if isinstance(msg, HumanMessage):\n",
        "        preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
        "        print(f\"\\n[{i}] ðŸ‘¤ USER: \\\"{preview}\\\"\")\n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT: Calling {msg.tool_calls[0]['name']}\")\n",
        "        else:\n",
        "            preview = msg.content[:80] + \"...\" if len(msg.content) > 80 else msg.content\n",
        "            print(f\"\\n[{i}] ðŸ¤– AGENT: \\\"{preview}\\\"\")\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"\\n[{i}] ðŸ”§ TOOL: Executed emi_calculator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show final response\n",
        "print(\"\\nFINAL RESPONSE:\")\n",
        "print(\"=\" * 70)\n",
        "print(result2[\"messages\"][-1].content)\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "âœ… **Complete message flow** - A single tool execution creates 4 messages: HumanMessage (user query) â†’ AIMessage with tool_calls (LLM decision) â†’ ToolMessage (tool result) â†’ AIMessage with content (final response)\n",
        "\n",
        "âœ… **Different message types** - Each message type serves a specific purpose: HumanMessage carries user input, AIMessage with tool_calls requests tool execution, ToolMessage returns results, AIMessage with content delivers the final answer\n",
        "\n",
        "âœ… **Execution cycle** - The graph flows through nodes: START â†’ LLM (decides to call tool) â†’ Tools (executes tool) â†’ LLM (synthesizes response) â†’ END\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Next, we'll explore **parallel tool execution** where the LLM calls multiple tools simultaneously in a single turn."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
