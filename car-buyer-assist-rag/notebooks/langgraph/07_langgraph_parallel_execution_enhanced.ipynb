{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Parallel Tool Execution\n",
        "\n",
        "Understanding how LangGraph executes multiple independent tools simultaneously.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. **Understand parallel execution** - When tasks are independent, the LLM calls multiple tools in a single request\n",
        "2. **Recognize the parallel pattern** - A single AIMessage contains multiple tool_calls that execute simultaneously\n",
        "3. **Verify parallel execution** - Examine message count and tool_calls structure to confirm parallel behavior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(\"../../.env\")\n",
        "print(\"âœ… Environment loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools\n",
        "@tool\n",
        "def currency_converter(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert currency from one type to another.\n",
        "    \n",
        "    Use this tool when users need to convert monetary amounts between\n",
        "    different currencies. Supports USD, EUR, GBP, INR, and JPY.\n",
        "    \"\"\"\n",
        "    exchange_rates = {\"USD\": 1.0, \"EUR\": 0.92, \"GBP\": 0.79, \"INR\": 83.12, \"JPY\": 149.50}\n",
        "    from_currency = from_currency.upper()\n",
        "    to_currency = to_currency.upper()\n",
        "    \n",
        "    if from_currency not in exchange_rates or to_currency not in exchange_rates:\n",
        "        return f\"Error: Unsupported currency\"\n",
        "    \n",
        "    amount_in_usd = amount / exchange_rates[from_currency]\n",
        "    converted_amount = amount_in_usd * exchange_rates[to_currency]\n",
        "    effective_rate = exchange_rates[to_currency] / exchange_rates[from_currency]\n",
        "    \n",
        "    return (\n",
        "        f\"Conversion Result:\\n\"\n",
        "        f\"  {amount:,.2f} {from_currency} = {converted_amount:,.2f} {to_currency}\\n\"\n",
        "        f\"  Exchange Rate: 1 {from_currency} = {effective_rate:.4f} {to_currency}\"\n",
        "    )\n",
        "\n",
        "@tool\n",
        "def emi_calculator(principal: float, annual_interest_rate: float, tenure_months: int, currency: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculate the EMI (Equated Monthly Installment) for a loan.\n",
        "    \n",
        "    Use this tool when users want to know their monthly loan payment,\n",
        "    total repayment amount, or total interest for a loan.\n",
        "    \"\"\"\n",
        "    if principal <= 0 or annual_interest_rate < 0 or tenure_months <= 0:\n",
        "        return \"Error: Invalid input parameters\"\n",
        "    \n",
        "    monthly_interest_rate = annual_interest_rate / 12 / 100\n",
        "    \n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = principal / tenure_months\n",
        "        total_payment = principal\n",
        "        total_interest = 0\n",
        "    else:\n",
        "        emi = principal * monthly_interest_rate * \\\n",
        "              pow(1 + monthly_interest_rate, tenure_months) / \\\n",
        "              (pow(1 + monthly_interest_rate, tenure_months) - 1)\n",
        "        total_payment = emi * tenure_months\n",
        "        total_interest = total_payment - principal\n",
        "    \n",
        "    return (\n",
        "        f\"EMI Calculation Result:\\n\"\n",
        "        f\"  Loan Amount: {principal:,.2f} {currency}\\n\"\n",
        "        f\"  Interest Rate: {annual_interest_rate}% per annum\\n\"\n",
        "        f\"  Tenure: {tenure_months} months\\n\"\n",
        "        f\"  Monthly EMI: {emi:,.2f} {currency}\\n\"\n",
        "        f\"  Total Payment: {total_payment:,.2f} {currency}\\n\"\n",
        "        f\"  Total Interest: {total_interest:,.2f} {currency}\"\n",
        "    )\n",
        "\n",
        "print(\"âœ… Tools defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize LLM and Build Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM and build graph\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "tools = [currency_converter, emi_calculator]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def call_llm(state: MessagesState):\n",
        "    \"\"\"LLM node: Calls LLM with current messages.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"Router: Check if agent wants to use tools.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# Build graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"llm\", call_llm)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_edge(START, \"llm\")\n",
        "workflow.add_conditional_edges(\"llm\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"llm\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"âœ… Graph compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Parallel Execution\n",
        "\n",
        "Query with **independent tasks** using \"AND ALSO\" to signal no dependencies between operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test parallel execution: Independent tasks\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 100000 USD to EUR AND ALSO calculate EMI for 500000 INR at 8.5% for 60 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result = app.invoke(state)\n",
        "print(f\"Total messages: {len(result['messages'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Parallel Tool Calls\n",
        "\n",
        "Check if multiple tools were called in a **single AIMessage**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify parallel tool calls - check for multiple tool_calls in single AIMessage\n",
        "tool_call_message = result['messages'][1]\n",
        "\n",
        "print(f\"Number of tool_calls: {len(tool_call_message.tool_calls)}\")\n",
        "\n",
        "if len(tool_call_message.tool_calls) > 1:\n",
        "    print(f\"\\nðŸš€ CONFIRMED: Parallel execution!\")\n",
        "    print(f\"   {len(tool_call_message.tool_calls)} tools called in a SINGLE AIMessage\")\n",
        "\n",
        "print(\"\\nTool Calls:\")\n",
        "for i, tc in enumerate(tool_call_message.tool_calls, 1):\n",
        "    print(f\"\\n  Tool {i}:\")\n",
        "    print(f\"    Name: {tc['name']}\")\n",
        "    print(f\"    Args: {tc['args']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examine Complete Messages\n",
        "\n",
        "Look at all messages to understand the parallel execution flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict(result['messages'][4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Message Flow Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine complete message flow\n",
        "print(\"MESSAGE FLOW:\\n\" + \"=\" * 70)\n",
        "\n",
        "for i, msg in enumerate(result[\"messages\"], 1):\n",
        "    print(f\"\\n[{i}] {type(msg).__name__}\")\n",
        "    \n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"    Content: {msg.content[:60]}...\")\n",
        "    elif isinstance(msg, AIMessage):\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            print(f\"    Requesting {len(msg.tool_calls)} tool(s) IN PARALLEL\")\n",
        "            for tc in msg.tool_calls:\n",
        "                print(f\"      â€¢ {tc['name']}\")\n",
        "        else:\n",
        "            print(f\"    Final response: {msg.content[:80]}...\")\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        first_line = msg.content.split('\\n')[0]\n",
        "        print(f\"    Result: {first_line}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show final response\n",
        "print(\"FINAL RESPONSE:\\n\" + \"=\" * 70)\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Streaming Execution\n",
        "\n",
        "Observe the parallel execution in real-time through streaming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stream execution to see real-time flow\n",
        "state_stream = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Convert 100000 USD to EUR AND ALSO calculate EMI for 500000 INR at 8.5% for 60 months\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"STREAMING EXECUTION\\n\" + \"=\" * 70)\n",
        "step_count = 0\n",
        "\n",
        "for event in app.stream(state_stream):\n",
        "    for node_name, data in event.items():\n",
        "        step_count += 1\n",
        "        print(f\"\\n[Step {step_count}] Node: '{node_name}'\")\n",
        "        \n",
        "        if \"messages\" in data:\n",
        "            for msg in data[\"messages\"]:\n",
        "                if isinstance(msg, AIMessage):\n",
        "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "                        print(f\"  ðŸš€ PARALLEL CALL: {len(msg.tool_calls)} tools requested\")\n",
        "                        for tc in msg.tool_calls:\n",
        "                            print(f\"     â€¢ {tc['name']}\")\n",
        "                    else:\n",
        "                        print(f\"  ðŸ’¬ Final response generated\")\n",
        "                elif isinstance(msg, ToolMessage):\n",
        "                    print(f\"  âœ… Tool executed\")\n",
        "\n",
        "print(f\"\\nTotal steps: {step_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "âœ… **Parallel execution** - When tasks are independent (no dependencies), the LLM calls multiple tools simultaneously in a single request, making the workflow more efficient\n",
        "\n",
        "âœ… **Parallel pattern** - A single AIMessage contains multiple tool_calls (e.g., `tool_calls: [currency_converter, emi_calculator]`), resulting in 5 total messages instead of 6+ for sequential execution\n",
        "\n",
        "âœ… **Verification** - Check `len(tool_calls)` in the AIMessage: if > 1, it's parallel execution; you'll see multiple ToolMessages returned before the final synthesis\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Next, we'll explore **sequential tool execution** where tasks have dependencies and must be executed one after another."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cbag-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
