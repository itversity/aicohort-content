{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 1 Assignment: Build Your Toyota RAG System\n",
        "\n",
        "**Name:** [Your Name]  \n",
        "**Date:** [Date]\n",
        "\n",
        "## Goal\n",
        "\n",
        "Build a complete RAG system that answers questions about Toyota vehicles.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Complete all TODO sections\n",
        "2. Run all cells and verify outputs\n",
        "3. Answer reflection questions at the end\n",
        "4. Submit this notebook with outputs visible\n",
        "\n",
        "## Grading\n",
        "\n",
        "- Correctness: 60 points\n",
        "- Code Quality: 20 points\n",
        "- Analysis: 20 points\n",
        "- **Total: 100 points**\n",
        "\n",
        "---\n",
        "\n",
        "Let's begin!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Environment Setup (5 points)\n",
        "\n",
        "Verify your environment is set up correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# TODO: Import pypdf, chromadb, and langchain_google_vertexai packages\n",
        "# Add your imports here\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"✓ Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Load Toyota PDFs (10 points)\n",
        "\n",
        "Implement the function to load PDF files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Load and extract text from a PDF file.\n",
        "    \n",
        "    Args:\n",
        "        pdf_path: Path to the PDF file\n",
        "        \n",
        "    Returns:\n",
        "        str: Full text content\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Steps:\n",
        "    # 1. Open the PDF file using pypdf.PdfReader\n",
        "    # 2. Loop through all pages\n",
        "    # 3. Extract text from each page\n",
        "    # 4. Concatenate all text\n",
        "    # 5. Return the full text\n",
        "    \n",
        "    pass  # Replace with your implementation\n",
        "\n",
        "# Test your function\n",
        "data_dir = Path(\"../data/car-specs/toyota-specs\")\n",
        "test_pdf = data_dir / \"Toyota_Camry_Specifications.pdf\"\n",
        "\n",
        "text = load_pdf(test_pdf)\n",
        "assert len(text) > 2000, \"Should extract substantial text\"\n",
        "print(f\"✓ Loaded {len(text)} characters from {test_pdf.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Implement Chunking (15 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_chunk(text, chunk_size=500, overlap=50):\n",
        "    \"\"\"\n",
        "    Split text into overlapping chunks.\n",
        "    \n",
        "    Args:\n",
        "        text: Text to chunk\n",
        "        chunk_size: Chunk size in characters\n",
        "        overlap: Overlap between chunks\n",
        "        \n",
        "    Returns:\n",
        "        list: List of text chunks\n",
        "    \"\"\"\n",
        "    # TODO: Implement chunking\n",
        "    # Hint: Use a while loop to iterate through text\n",
        "    # Create chunks of chunk_size with overlap\n",
        "    \n",
        "    pass  # Replace with your implementation\n",
        "\n",
        "# Test chunking\n",
        "test_text = \"A\" * 1000\n",
        "test_chunks = simple_chunk(test_text, chunk_size=500, overlap=50)\n",
        "assert len(test_chunks) >= 2, \"Should create multiple chunks\"\n",
        "print(f\"✓ Chunking works! Created {len(test_chunks)} chunks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: ChromaDB Storage (20 points)\n",
        "\n",
        "Store all chunks in ChromaDB vector database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize ChromaDB and create collection\n",
        "# Your code here\n",
        "\n",
        "# TODO: Load all PDFs and chunk them\n",
        "# Your code here\n",
        "\n",
        "# TODO: Store chunks in ChromaDB\n",
        "# Prepare documents, metadatas, and ids lists\n",
        "# Use collection.add() method\n",
        "\n",
        "print(f\"✓ Stored chunks in ChromaDB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Complete RAG Function (20 points)\n",
        "\n",
        "Implement the complete RAG pipeline function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_toyota_question(question, collection, llm):\n",
        "    \"\"\"\n",
        "    Ask a question about Toyota using RAG.\n",
        "    \n",
        "    Args:\n",
        "        question: User's question\n",
        "        collection: ChromaDB collection\n",
        "        llm: Language model (Gemini Pro)\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (answer, sources)\n",
        "    \"\"\"\n",
        "    # TODO: Implement RAG function\n",
        "    # Steps:\n",
        "    # 1. Query collection to retrieve top 3 chunks\n",
        "    # 2. Build context from retrieved documents\n",
        "    # 3. Create prompt with context and question\n",
        "    # 4. Generate answer using llm.invoke()\n",
        "    # 5. Return answer and sources\n",
        "    \n",
        "    pass  # Replace with your implementation\n",
        "\n",
        "# TODO: Initialize Gemini Pro LLM\n",
        "# from langchain_google_vertexai import VertexAI\n",
        "# llm = VertexAI(model_name=\"gemini-pro\", temperature=0)\n",
        "\n",
        "# Test your RAG function\n",
        "# answer, sources = ask_toyota_question(\"What's the Camry's horsepower?\", collection, llm)\n",
        "# print(f\"Answer: {answer}\")\n",
        "# print(f\"Sources: {[s['model'] for s in sources]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Reflection Questions (20 points)\n",
        "\n",
        "Answer the following questions based on your experience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1: Chunking Strategy\n",
        "\n",
        "What are the advantages and disadvantages of our simple 500-character chunking approach? When might it fail?\n",
        "\n",
        "**Your Answer:**  \n",
        "[Write your answer here - 3-4 sentences]\n",
        "\n",
        "### Question 2: Retrieval Quality\n",
        "\n",
        "Which query types (specification, feature, general) worked best? Why?\n",
        "\n",
        "**Your Answer:**  \n",
        "[Write your answer here - 3-4 sentences]\n",
        "\n",
        "### Question 3: Improvements\n",
        "\n",
        "If you could improve one part of this RAG system, what would it be and why?\n",
        "\n",
        "**Your Answer:**  \n",
        "[Write your answer here - 2-3 sentences]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
