{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 1: RAG Foundations - Lecture Demo\n",
        "\n",
        "**Goal:** Build a complete RAG system for Toyota specifications\n",
        "\n",
        "**What we'll build:**\n",
        "- Load and analyze Toyota PDF documents\n",
        "- Implement simple chunking strategy\n",
        "- Create embeddings with Vertex AI\n",
        "- Store in ChromaDB vector database\n",
        "- Query and retrieve relevant information\n",
        "- Generate answers with Gemini Pro\n",
        "\n",
        "**Duration:** 2 hours live session\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Environment Setup and Data Exploration\n",
        "\n",
        "First, let's verify our environment and explore the Toyota dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GCP Configuration:\n",
            "======================================================================\n",
            "Project ID: agentapps-473813\n",
            "Region: us-central1\n",
            "\n",
            "✓ Environment variables loaded\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Verify GCP configuration\n",
        "print(\"GCP Configuration:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project ID: {os.getenv('GCP_PROJECT_ID')}\")\n",
        "print(f\"Region: {os.getenv('GCP_REGION', 'us-central1')}\")\n",
        "print(\"\\n✓ Environment variables loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.11.2 (v3.11.2:878ead1ac1, Feb  7 2023, 10:02:41) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
            "Python executable: /Users/itversity/Projects/Internal/aicohort-content/.venv/bin/python\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/itversity/Projects/Internal/aicohort-content/.venv/lib/python3.11/site-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
            "  from google.cloud.aiplatform.utils import gcs_utils\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ All required packages are installed!\n"
          ]
        }
      ],
      "source": [
        "# Check Python version and key imports\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Python executable: {sys.executable}\")\n",
        "\n",
        "# Verify key packages are installed\n",
        "try:\n",
        "    import pypdf\n",
        "    import chromadb\n",
        "    from langchain_google_vertexai import VertexAIEmbeddings, VertexAI\n",
        "    print(\"\\n✓ All required packages are installed!\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\n❌ Missing package: {e}\")\n",
        "    print(\"Run: pip install -r requirements.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Explore Toyota Dataset - File Sizes\n",
        "\n",
        "Let's see what PDF files we have and their sizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toyota Specifications Dataset\n",
            "======================================================================\n",
            "Filename                                      Size (KB)  Pages\n",
            "----------------------------------------------------------------------\n",
            "Introduction_to_Toyota_Car_Sales.pdf             48.6 KB     2\n",
            "Toyota_Camry_Specifications.pdf                  74.3 KB     1\n",
            "Toyota_Corolla_Specifications.pdf                73.4 KB     1\n",
            "Toyota_Highlander_Specifications.pdf             74.9 KB     1\n",
            "Toyota_Prius_Specifications.pdf                  74.9 KB     1\n",
            "Toyota_RAV4_Specifications.pdf                   75.9 KB     1\n",
            "Toyota_Tacoma_Specifications.pdf                 73.6 KB     1\n",
            "Toyota_bZ4X_Specifications.pdf                   83.9 KB     4\n",
            "----------------------------------------------------------------------\n",
            "Total                                           579.5 KB\n",
            "\n",
            "✓ Found 8 Toyota specification documents\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Path to Toyota specs directory\n",
        "data_dir = Path(\"../data/car-specs/toyota-specs\")\n",
        "\n",
        "# List all PDF files with sizes\n",
        "pdfs = sorted(data_dir.glob(\"*.pdf\"))\n",
        "\n",
        "print(\"Toyota Specifications Dataset\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Filename':<45} {'Size (KB)':<10} {'Pages'}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "total_size = 0\n",
        "for pdf in pdfs:\n",
        "    size_kb = os.path.getsize(pdf) / 1024\n",
        "    total_size += size_kb\n",
        "    \n",
        "    # Get page count\n",
        "    with open(pdf, 'rb') as f:\n",
        "        reader = pypdf.PdfReader(f)\n",
        "        pages = len(reader.pages)\n",
        "    \n",
        "    print(f\"{pdf.name:<45} {size_kb:>7.1f} KB {pages:>5}\")\n",
        "\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Total':<45} {total_size:>7.1f} KB\")\n",
        "print(f\"\\n✓ Found {len(pdfs)} Toyota specification documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Load PDF and Analyze Content\n",
        "\n",
        "Extract text from Toyota Camry PDF and analyze it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toyota Camry Text Analysis\n",
            "======================================================================\n",
            "Total characters: 3,073\n",
            "Total words: 434\n",
            "Total lines: 68\n",
            "\n",
            "First 500 characters:\n",
            "----------------------------------------------------------------------\n",
            "rag/Toyota_Camry_Specifications.md\n",
            "Toyota Camry: The Sophisticated Midsize Sedan\n",
            "Overview\n",
            "The Toyota Camry is a premium midsize sedan renowned for its reliability, spacious interiors, and smooth performance. It caters to\n",
            "professionals, small families, and those seeking a balance of luxury and efﬁciency, with hybrid options available for eco-conscious buyers.\n",
            "Engine Options\n",
            "2.5L 4-Cylinder Gasoline Engine\n",
            "Power Output: 203 HP\n",
            "Transmission: 8-speed automatic\n",
            "Key Feature: Efﬁcient and reﬁned perfor\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "def load_pdf(pdf_path):\n",
        "    \"\"\"Load and extract text from a PDF file.\"\"\"\n",
        "    with open(pdf_path, 'rb') as f:\n",
        "        reader = pypdf.PdfReader(f)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Load Toyota Camry specifications\n",
        "camry_path = data_dir / \"Toyota_Camry_Specifications.pdf\"\n",
        "camry_text = load_pdf(camry_path)\n",
        "\n",
        "# Analyze the text\n",
        "print(\"Toyota Camry Text Analysis\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total characters: {len(camry_text):,}\")\n",
        "print(f\"Total words: {len(camry_text.split()):,}\")\n",
        "\n",
        "# Fix: Calculate line count before the f-string\n",
        "line_count = len([l for l in camry_text.split('\\n') if l.strip()])\n",
        "print(f\"Total lines: {line_count:,}\")\n",
        "\n",
        "print(\"\\nFirst 500 characters:\")\n",
        "print(\"-\"*70)\n",
        "print(camry_text[:500])\n",
        "print(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Load All Documents\n",
        "\n",
        "Load all 8 Toyota PDFs into memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Loaded: Introduction to Toyota Car Sales (1,871 characters)\n",
            "✓ Loaded: Toyota Camry                   (3,073 characters)\n",
            "✓ Loaded: Toyota Corolla                 (2,685 characters)\n",
            "✓ Loaded: Toyota Highlander              (2,877 characters)\n",
            "✓ Loaded: Toyota Prius                   (3,310 characters)\n",
            "✓ Loaded: Toyota RAV4                    (3,174 characters)\n",
            "✓ Loaded: Toyota Tacoma                  (2,668 characters)\n",
            "✓ Loaded: Toyota bZ4X                    (3,090 characters)\n",
            "\n",
            "✓ Successfully loaded 8 documents\n"
          ]
        }
      ],
      "source": [
        "# Load all Toyota PDFs\n",
        "documents = []\n",
        "\n",
        "for pdf in sorted(pdfs):\n",
        "    text = load_pdf(pdf)\n",
        "    model = pdf.stem.replace(\"_\", \" \").replace(\" Specifications\", \"\")\n",
        "    \n",
        "    documents.append({\n",
        "        \"content\": text,\n",
        "        \"source\": pdf.name,\n",
        "        \"model\": model\n",
        "    })\n",
        "    print(f\"✓ Loaded: {model:<30} ({len(text):,} characters)\")\n",
        "\n",
        "print(f\"\\n✓ Successfully loaded {len(documents)} documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Chunking Strategy\n",
        "\n",
        "Break documents into smaller chunks for better retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Introduction to Toyota Car Sales ->   5 chunks\n",
            "✓ Toyota Camry                   ->   7 chunks\n",
            "✓ Toyota Corolla                 ->   6 chunks\n",
            "✓ Toyota Highlander              ->   7 chunks\n",
            "✓ Toyota Prius                   ->   8 chunks\n",
            "✓ Toyota RAV4                    ->   7 chunks\n",
            "✓ Toyota Tacoma                  ->   6 chunks\n",
            "✓ Toyota bZ4X                    ->   7 chunks\n",
            "\n",
            "✓ Created 53 chunks from 8 documents\n"
          ]
        }
      ],
      "source": [
        "def simple_chunk(text, chunk_size=500, overlap=50):\n",
        "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    \n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        \n",
        "        if chunk.strip():\n",
        "            chunks.append(chunk)\n",
        "        \n",
        "        start = end - overlap\n",
        "        \n",
        "        if start >= len(text) - overlap:\n",
        "            break\n",
        "    \n",
        "    return chunks\n",
        "\n",
        "# Chunk all documents\n",
        "all_chunks = []\n",
        "\n",
        "for doc in documents:\n",
        "    chunks = simple_chunk(doc[\"content\"], chunk_size=500, overlap=50)\n",
        "    \n",
        "    for i, chunk in enumerate(chunks):\n",
        "        all_chunks.append({\n",
        "            \"content\": chunk,\n",
        "            \"model\": doc[\"model\"],\n",
        "            \"source\": doc[\"source\"],\n",
        "            \"chunk_id\": f\"{doc['source']}_{i}\"\n",
        "        })\n",
        "    \n",
        "    print(f\"✓ {doc['model']:<30} -> {len(chunks):>3} chunks\")\n",
        "\n",
        "print(f\"\\n✓ Created {len(all_chunks)} chunks from {len(documents)} documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: ChromaDB Storage\n",
        "\n",
        "Store chunks with embeddings for semantic search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your browser has been opened to visit:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=PVQJDNzoxVHGSf36RgUMHaB8N05ykx&access_type=offline&code_challenge=ge4H0PwMBSpQbRurdX1hIG8fZeFDZFGdS-4Q3Lyg4-I&code_challenge_method=S256\n",
            "\n",
            "\n",
            "Credentials saved to file: [/Users/itversity/.config/gcloud/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"agentapps-473813\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n",
            "\n",
            "\n",
            "Updates are available for some Google Cloud CLI components.  To install them,\n",
            "please run:\n",
            "  $ gcloud components update\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'agentapps-473813'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getenv(\"GCP_PROJECT_ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from chromadb.api.types import EmbeddingFunction, Documents\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom wrapper to adapt LangChain embeddings to ChromaDB interface\n",
        "class VertexAIEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, model_name: str, project: str, location: str):\n",
        "        self.embeddings = VertexAIEmbeddings(\n",
        "            model_name=model_name,\n",
        "            project=project,\n",
        "            location=location\n",
        "        )\n",
        "    \n",
        "    def __call__(self, input: Documents) -> list:\n",
        "        \"\"\"Embed documents using Vertex AI\"\"\"\n",
        "        return self.embeddings.embed_documents(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Vertex AI embeddings...\n"
          ]
        }
      ],
      "source": [
        "# Initialize Vertex AI embeddings wrapper\n",
        "print(\"Initializing Vertex AI embeddings...\")\n",
        "embedding_function = VertexAIEmbeddingFunction(\n",
        "    model_name=\"text-embedding-004\",\n",
        "    project=os.getenv(\"GCP_PROJECT_ID\"),\n",
        "    location=os.getenv(\"GCP_REGION\", \"us-central1\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ChromaDB with Vertex AI embeddings\n",
        "client = chromadb.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Deleted existing collection\n"
          ]
        }
      ],
      "source": [
        "# Delete collection if it exists (for clean state)\n",
        "try:\n",
        "    client.delete_collection(name=\"toyota_specs_week1\")\n",
        "    print(\"✓ Deleted existing collection\")\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create new collection\n",
        "collection = client.create_collection(\n",
        "    name=\"toyota_specs_week1\",\n",
        "    embedding_function=embedding_function,\n",
        "    metadata={\"description\": \"Toyota specifications - Week 1 demo\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "documents_list = [chunk[\"content\"] for chunk in all_chunks]\n",
        "metadatas = [{\"model\": chunk[\"model\"], \"source\": chunk[\"source\"]} for chunk in all_chunks]\n",
        "ids = [chunk[\"chunk_id\"] for chunk in all_chunks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding chunks to ChromaDB (creating embeddings with Vertex AI)...\n",
            "✓ Stored 53 chunks in ChromaDB with Vertex AI embeddings\n"
          ]
        }
      ],
      "source": [
        "# Add to collection (will use Vertex AI for embeddings)\n",
        "print(\"Adding chunks to ChromaDB (creating embeddings with Vertex AI)...\")\n",
        "collection.add(documents=documents_list, metadatas=metadatas, ids=ids)\n",
        "\n",
        "print(f\"✓ Stored {collection.count()} chunks in ChromaDB with Vertex AI embeddings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Query and Retrieve\n",
        "\n",
        "Test semantic search - find relevant chunks for a query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'What is the Toyota Camry's horsepower?'\\n\n",
            "Retrieving top 3 relevant chunks...\\n\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the Toyota Camry's horsepower?\"\n",
        "\n",
        "print(f\"Query: '{query}'\\\\n\")\n",
        "print(\"Retrieving top 3 relevant chunks...\\\\n\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query ChromaDB\n",
        "results = collection.query(query_texts=[query], n_results=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nResult 1:\n",
            "  Model: Toyota Camry\n",
            "  Similarity: 0.7040\n",
            "  Content: rag/Toyota_Camry_Specifications.md\n",
            "Toyota Camry: The Sophisticated Midsize Sedan\n",
            "Overview\n",
            "The Toyota Camry is a premium midsize sedan renowned for its...\n",
            "----------------------------------------------------------------------\n",
            "\\nResult 2:\n",
            "  Model: Toyota Camry\n",
            "  Similarity: 0.6471\n",
            "  Content: ront-Wheel Drive) only\n",
            "What is the warranty for the Toyota Camry?\n",
            "3 years/36,000 miles basic warranty and 5 years/60,000 miles powertrain warranty\n",
            "Qui...\n",
            "----------------------------------------------------------------------\n",
            "\\nResult 3:\n",
            "  Model: Toyota Camry\n",
            "  Similarity: 0.5994\n",
            "  Content: fessionals: Modern interiors and advanced tech for a sophisticated experience\n",
            "Eco-Conscious Buyers: Hybrid models with outstanding fuel efﬁciency\n",
            "Smal...\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "for i, (doc, metadata, distance) in enumerate(zip(\n",
        "    results['documents'][0],\n",
        "    results['metadatas'][0],\n",
        "    results['distances'][0]\n",
        "), 1):\n",
        "    print(f\"\\\\nResult {i}:\")\n",
        "    print(f\"  Model: {metadata['model']}\")\n",
        "    print(f\"  Similarity: {1 - distance:.4f}\")\n",
        "    print(f\"  Content: {doc[:150]}...\")\n",
        "    print(\"-\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Generate Answer with Gemini Pro\n",
        "\n",
        "Use the LLM to generate a natural language answer based on retrieved context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Gemini Pro\n",
        "llm = VertexAI(model_name=\"gemini-2.5-pro\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Question: What is the Toyota Camry's horsepower?\n",
            "======================================================================\n",
            "Answer: The horsepower of the Toyota Camry depends on the engine you choose:\n",
            "\n",
            "*   The 2.5L 4-cylinder gasoline engine has **203 horsepower**.\n",
            "*   The V6 gasoline engine has **301 horsepower**.\n",
            "*   The hybrid models have a combined horsepower of **208**.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Build prompt with context\n",
        "context = \"\\\\n\\\\n\".join(results['documents'][0])\n",
        "\n",
        "prompt = f\"\"\"You are a helpful Toyota sales assistant. Answer the customer's question based on the provided information.\n",
        "\n",
        "Context from Toyota specifications:\n",
        "{context}\n",
        "\n",
        "Customer question: {query}\n",
        "\n",
        "Provide a clear, accurate answer. If the information isn't in the context, say so.\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "# Generate answer\n",
        "answer = llm.invoke(prompt)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(f\"Question: {query}\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Answer: {answer}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Complete RAG Function\n",
        "\n",
        "Wrap everything into a reusable function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_toyota_question(question, collection, llm):\n",
        "    \"\"\"\n",
        "    Ask a question about Toyota vehicles using RAG.\n",
        "    \n",
        "    Args:\n",
        "        question: User's question\n",
        "        collection: ChromaDB collection\n",
        "        llm: Language model\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (answer, sources)\n",
        "    \"\"\"\n",
        "    # Retrieve\n",
        "    results = collection.query(query_texts=[question], n_results=3)\n",
        "    \n",
        "    # Build context\n",
        "    context = \"\\\\n\\\\n\".join(results['documents'][0])\n",
        "    sources = results['metadatas'][0]\n",
        "    \n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"You are a helpful Toyota sales assistant. Answer based on the provided information.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    \n",
        "    # Generate\n",
        "    answer = llm.invoke(prompt)\n",
        "    \n",
        "    return answer, sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with multiple queries\n",
        "test_queries = [\n",
        "    \"What's the Camry's horsepower?\",\n",
        "    \"What safety features does the RAV4 have?\",\n",
        "    \"Tell me about Toyota reliability\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Complete RAG System\n",
            "======================================================================\n",
            "\\n1. Q: What's the Camry's horsepower?\n",
            "   A: Based on the provided information, the Toyota Camry with the 2.5L 4-Cylinder gasoline engine has a power output of 203 HP.\n",
            "   Sources: ['Toyota Camry', 'Toyota Camry', 'Toyota Camry']\n",
            "\\n2. Q: What safety features does the RAV4 have?\n",
            "   A: Based on the information provided, the Toyota RAV4 has \"top-tier safety features,\" which make it an ideal vehicle for families.\n",
            "   Sources: ['Toyota RAV4', 'Toyota RAV4', 'Toyota RAV4']\n",
            "\\n3. Q: Tell me about Toyota reliability\n",
            "   A: Based on the information provided, Toyota has long been known for its reliability.\n",
            "\n",
            "Specifically, the Toyota Corolla is renowned for its long-term reliability and resale value, especially when compared to competitors like the Hyundai Elantra.\n",
            "   Sources: ['Introduction to Toyota Car Sales', 'Introduction to Toyota Car Sales', 'Toyota Corolla']\n"
          ]
        }
      ],
      "source": [
        "print(\"Testing Complete RAG System\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, q in enumerate(test_queries, 1):\n",
        "    print(f\"\\\\n{i}. Q: {q}\")\n",
        "    answer, sources = ask_toyota_question(q, collection, llm)\n",
        "    print(f\"   A: {answer}\")\n",
        "    print(f\"   Sources: {[s['model'] for s in sources]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
